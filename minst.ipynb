{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Gebruiker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan for creating Neural Network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Gebruiker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "#loading the dataset\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "#printing the shapes of the vectors \n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the error margin, we will use back prop to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example loading data, replace this with your actual data loading code\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "# Reshape the images from (number_of_images, 28, 28) to (number_of_images, 784)\n",
    "train_X_flattened = train_X.reshape(train_X.shape[0], -1)\n",
    "test_X_flattened = test_X.reshape(test_X.shape[0], -1)\n",
    "\n",
    "# Normalize the pixel values to the range [0, 1]\n",
    "train_X_flattened = train_X_flattened / 255.0\n",
    "test_X_flattened = test_X_flattened / 255.0\n",
    "\n",
    "# Transpose the data if each column should represent an image\n",
    "train_X_flattened = train_X_flattened.T\n",
    "test_X_flattened = test_X_flattened.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    \"\"\"\n",
    "    Initialize the parameters of a 2-layer neural network.\n",
    "    The network has 784 input features and 10 output units in each layer.\n",
    "    \n",
    "    Returns:\n",
    "    W1, b1: Weight and bias for the first layer.\n",
    "    W2, b2: Weight and bias for the second layer.\n",
    "    \"\"\"\n",
    "    W1 = np.random.normal(size=(10, 784)) * np.sqrt(1./(784))\n",
    "    #b1 = np.random.normal(size=(10, 1)) * np.sqrt(1./10)\n",
    "    b1 = np.zeros((10, 1))\n",
    "    W2 = np.random.normal(size=(10, 10)) * np.sqrt(1./20)\n",
    "    #b2 = np.random.normal(size=(10, 1)) * np.sqrt(1./(784))\n",
    "    b2 = np.zeros((10, 1))\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    \"\"\"\n",
    "    Apply the Rectified Linear Unit (ReLU) function element-wise.\n",
    "    \n",
    "    Z: Input array.\n",
    "    \n",
    "    Returns:\n",
    "    Array with ReLU applied (all negative elements set to 0).\n",
    "    \"\"\"\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "\n",
    "def LeakyReLU(Z, alpha=0.01):\n",
    "    return np.where(Z > 0, Z, alpha * Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    \"\"\"\n",
    "    Apply the softmax function to each column of the input array.\n",
    "    \n",
    "    Z: Input array.\n",
    "    \n",
    "    Returns:\n",
    "    Softmax applied array.\n",
    "    \"\"\"\n",
    "    Z -= np.max(Z, axis=0)  # Improve numerical stability\n",
    "    exp_Z = np.exp(Z)\n",
    "    return exp_Z / (np.sum(exp_Z, axis=0, keepdims=True) + 1e-8)\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    \"\"\"\n",
    "    Perform forward propagation through the network.\n",
    "    \n",
    "    W1, b1: Weight and bias for the first layer.\n",
    "    W2, b2: Weight and bias for the second layer.\n",
    "    X: Input data (each column is an input example).\n",
    "    \n",
    "    Returns:\n",
    "    Z1, A1: Pre-activation and post-activation values for the first layer.\n",
    "    Z2, A2: Pre-activation and post-activation values for the second layer.\n",
    "    \"\"\"\n",
    "    Z1 = W1.dot(X) + b1       # Linear step for layer 1\n",
    "    A1 = LeakyReLU(Z1)             # Activation step for layer 1\n",
    "    Z2 = W2.dot(A1) + b2      # Linear step for layer 2\n",
    "    A2 = softmax(Z2)          # Activation step for layer 2 (softmax)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot(Y):\n",
    "    \"\"\"\n",
    "    Convert a vector of labels to one-hot encoding.\n",
    "    \n",
    "    Y: Input array of labels.\n",
    "    \n",
    "    Returns:\n",
    "    One-hot encoded matrix.\n",
    "    \"\"\"\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def deriv_ReLU(Z):\n",
    "    \"\"\"\n",
    "    Compute the derivative of the ReLU function.\n",
    "    \n",
    "    Z: Input array.\n",
    "    \n",
    "    Returns:\n",
    "    Array with derivatives of ReLU.\n",
    "    \"\"\"\n",
    "    return Z > 0\n",
    "\n",
    "\n",
    "def deriv_LeakyReLU(Z, alpha=0.01):\n",
    "    return np.where(Z > 0, 1, alpha)\n",
    "\n",
    "def back_prop(Z1, A1, Z2, A2, W2, X, Y):\n",
    "    \"\"\"\n",
    "    Perform backpropagation to compute gradients.\n",
    "    \n",
    "    Z1, A1: Pre-activation and post-activation values for the first layer.\n",
    "    Z2, A2: Pre-activation and post-activation values for the second layer.\n",
    "    W2: Weight matrix for the second layer.\n",
    "    X: Input data.\n",
    "    Y: True labels.\n",
    "    \n",
    "    Returns:\n",
    "    dW1, db1: Gradients of loss with respect to W1 and b1.\n",
    "    dW2, db2: Gradients of loss with respect to W2 and b2.\n",
    "    \"\"\"\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y        # Derivative of loss with respect to Z2\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T) # Gradient of loss with respect to W2\n",
    "    db2 = 1 / m * np.sum(dZ2, axis=1, keepdims=True) # Gradient of loss with respect to b2; corrected axis\n",
    "    dZ1 = W2.T.dot(dZ2) * deriv_LeakyReLU(Z1) # Derivative of loss with respect to Z1\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)  # Gradient of loss with respect to W1\n",
    "    db1 = 1 / m * np.sum(dZ1, axis=1, keepdims=True) # Gradient of loss with respect to b1; corrected axis\n",
    "\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    \"\"\"\n",
    "    Update the parameters of the network using gradient descent.\n",
    "    \n",
    "    W1, b1: Current weight and bias for the first layer.\n",
    "    W2, b2: Current weight and bias for the second layer.\n",
    "    dW1, db1: Gradients for W1 and b1.\n",
    "    dW2, db2: Gradients for W2 and b2.\n",
    "    alpha: Learning rate.\n",
    "    \n",
    "    Returns:\n",
    "    Updated W1, b1, W2, b2.\n",
    "    \"\"\"\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * np.reshape(db1, (10, 1))\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * np.reshape(db2, (10, 1))\n",
    "\n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    \"\"\"\n",
    "    Generate predictions from the output layer's activations.\n",
    "\n",
    "    A2: The output activations from the last layer of the neural network, \n",
    "        where each column corresponds to the activations for a given input example.\n",
    "\n",
    "    Returns:\n",
    "    An array of predicted class labels for each input example.\n",
    "    \"\"\"\n",
    "    return np.argmax(A2, 0)  # np.argmax returns the indices of the max values along axis 0.\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of predictions against the true labels.\n",
    "\n",
    "    predictions: An array of predicted class labels.\n",
    "    Y: The true labels.\n",
    "\n",
    "    Returns:\n",
    "    The accuracy as a float.\n",
    "    \"\"\"\n",
    "    print(predictions, Y)  # Optionally print the predictions and true labels for inspection.\n",
    "    return np.sum(predictions == Y) / Y.size  # Calculate the proportion of correct predictions.\n",
    "\n",
    "def compute_loss(A2, Y):\n",
    "    m = Y.shape[1]\n",
    "    loss = -np.sum(Y * np.log(A2)) / m\n",
    "    return loss\n",
    "\n",
    "def gradient_descent(X, Y, iterations, alpha, W1=None, b1=None, W2=None, b2=None):\n",
    "    \"\"\"\n",
    "    Perform gradient descent to train the neural network.\n",
    "\n",
    "    X: Input data, where each column is an input example (e.g., a flattened image).\n",
    "    Y: True labels for the input data.\n",
    "    iterations: The number of iterations to train the network.\n",
    "    alpha: The learning rate.\n",
    "\n",
    "    Returns:\n",
    "    The final weights and biases after training.\n",
    "    \"\"\"\n",
    "    if W1 is None or b1 is None or W2 is None or b2 is None:\n",
    "        W1, b1, W2, b2 = init_params()  # Initialize parameters.\n",
    "        \n",
    "    for i in range(iterations):\n",
    "        # Forward propagation.\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "\n",
    "        # Backward propagation.\n",
    "        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W2, X, Y)\n",
    "\n",
    "        # Update parameters.\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "\n",
    "        # Print accuracy every 50 iterations.\n",
    "        if i % 50 == 0:\n",
    "            loss = compute_loss(A2, one_hot(Y))\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(\"Iteration: \", i, \"Loss: \", loss, \"Accuracy: \", get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "iterations = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[2 0 9 ... 9 0 2] [5 0 4 ... 5 6 8]\n",
      "Iteration:  0 Loss:  2.2881517273087946 Accuracy:  0.1333\n",
      "Iteration:  50\n",
      "[3 0 3 ... 9 0 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  50 Loss:  1.7508805623358452 Accuracy:  0.5039\n",
      "Iteration:  100\n",
      "[3 0 4 ... 9 0 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  100 Loss:  1.2329154876591089 Accuracy:  0.7041166666666666\n",
      "Iteration:  150\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  150 Loss:  0.8583140430423932 Accuracy:  0.8090333333333334\n",
      "Iteration:  200\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  200 Loss:  0.6665745349034801 Accuracy:  0.8394666666666667\n",
      "Iteration:  250\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  250 Loss:  0.5701338941059922 Accuracy:  0.8559666666666667\n",
      "Iteration:  300\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  300 Loss:  0.5124126652323541 Accuracy:  0.8657\n",
      "Iteration:  350\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  350 Loss:  0.4734855105529864 Accuracy:  0.8740166666666667\n",
      "Iteration:  400\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  400 Loss:  0.44516683975387894 Accuracy:  0.8793166666666666\n",
      "Iteration:  450\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  450 Loss:  0.4234945778272493 Accuracy:  0.8841333333333333\n",
      "Iteration:  500\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  500 Loss:  0.40626399412226105 Accuracy:  0.8885833333333333\n",
      "Iteration:  550\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  550 Loss:  0.39219496209335586 Accuracy:  0.8914\n",
      "Iteration:  600\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  600 Loss:  0.38047664217965815 Accuracy:  0.8937166666666667\n",
      "Iteration:  650\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  650 Loss:  0.37055245515277413 Accuracy:  0.89595\n",
      "Iteration:  700\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  700 Loss:  0.36202482980685685 Accuracy:  0.8984666666666666\n",
      "Iteration:  750\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  750 Loss:  0.3546170736689824 Accuracy:  0.9003\n",
      "Iteration:  800\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  800 Loss:  0.34811858389277334 Accuracy:  0.9016333333333333\n",
      "Iteration:  850\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  850 Loss:  0.34236502701045274 Accuracy:  0.9027833333333334\n",
      "Iteration:  900\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  900 Loss:  0.33723358893153654 Accuracy:  0.90395\n",
      "Iteration:  950\n",
      "[3 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  950 Loss:  0.3326115326352874 Accuracy:  0.9049666666666667\n",
      "Iteration:  1000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1000 Loss:  0.3284344607951646 Accuracy:  0.9059666666666667\n",
      "Iteration:  1050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1050 Loss:  0.3246373937810277 Accuracy:  0.9068333333333334\n",
      "Iteration:  1100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1100 Loss:  0.321163702110094 Accuracy:  0.9079166666666667\n",
      "Iteration:  1150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1150 Loss:  0.31797293276486993 Accuracy:  0.9088666666666667\n",
      "Iteration:  1200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1200 Loss:  0.31502472461842845 Accuracy:  0.9095333333333333\n",
      "Iteration:  1250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1250 Loss:  0.3122864798665663 Accuracy:  0.9100833333333334\n",
      "Iteration:  1300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1300 Loss:  0.30973651176683253 Accuracy:  0.91085\n",
      "Iteration:  1350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1350 Loss:  0.30735142669088755 Accuracy:  0.91145\n",
      "Iteration:  1400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1400 Loss:  0.3051162039262056 Accuracy:  0.9120333333333334\n",
      "Iteration:  1450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1450 Loss:  0.30301556018963727 Accuracy:  0.9127166666666666\n",
      "Iteration:  1500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1500 Loss:  0.3010386757274251 Accuracy:  0.9131666666666667\n",
      "Iteration:  1550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1550 Loss:  0.29917133319373923 Accuracy:  0.9139166666666667\n",
      "Iteration:  1600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1600 Loss:  0.29740237646291895 Accuracy:  0.91455\n",
      "Iteration:  1650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1650 Loss:  0.29571854476775783 Accuracy:  0.9153166666666667\n",
      "Iteration:  1700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1700 Loss:  0.2941104467861024 Accuracy:  0.9156166666666666\n",
      "Iteration:  1750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1750 Loss:  0.29257857030132356 Accuracy:  0.91615\n",
      "Iteration:  1800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1800 Loss:  0.29111679613395497 Accuracy:  0.9167333333333333\n",
      "Iteration:  1850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1850 Loss:  0.2897179633552255 Accuracy:  0.9171833333333334\n",
      "Iteration:  1900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1900 Loss:  0.2883786710193749 Accuracy:  0.91765\n",
      "Iteration:  1950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1950 Loss:  0.2870907411903593 Accuracy:  0.918\n",
      "Iteration:  2000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2000 Loss:  0.28585146253807453 Accuracy:  0.91845\n",
      "Iteration:  2050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2050 Loss:  0.28466124117308234 Accuracy:  0.91885\n",
      "Iteration:  2100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2100 Loss:  0.2835124178656014 Accuracy:  0.9192\n",
      "Iteration:  2150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2150 Loss:  0.28240432991558345 Accuracy:  0.9194166666666667\n",
      "Iteration:  2200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2200 Loss:  0.2813326916771444 Accuracy:  0.9196166666666666\n",
      "Iteration:  2250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2250 Loss:  0.2802954712503602 Accuracy:  0.9199666666666667\n",
      "Iteration:  2300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2300 Loss:  0.2792928680042649 Accuracy:  0.9202833333333333\n",
      "Iteration:  2350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2350 Loss:  0.27832150644176484 Accuracy:  0.9203833333333333\n",
      "Iteration:  2400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2400 Loss:  0.2773798756729774 Accuracy:  0.9207\n",
      "Iteration:  2450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2450 Loss:  0.2764671894186883 Accuracy:  0.92105\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(train_X_flattened, train_y, iterations, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_model_version(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        return 0  # No models saved yet\n",
    "\n",
    "    model_files = [f for f in os.listdir(directory) if re.match(r'model_v\\d+\\.pkl', f)]\n",
    "    if not model_files:\n",
    "        return 0  # No versioned model files found\n",
    "\n",
    "    # Extract version numbers and find the maximum\n",
    "    versions = [int(re.search(r'(\\d+)', f).group()) for f in model_files]\n",
    "    return max(versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(W1, b1, W2, b2, directory='models'):\n",
    "    latest_version = get_latest_model_version(directory)\n",
    "    next_version = latest_version + 1\n",
    "    filename = f'model_v{next_version}.pkl'\n",
    "    filepath = os.path.join(directory, filename)\n",
    "\n",
    "    model_params = {\n",
    "        'W1': W1,\n",
    "        'b1': b1,\n",
    "        'W2': W2,\n",
    "        'b2': b2\n",
    "    }\n",
    "\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pickle.dump(model_params, file)\n",
    "    print(f\"Model saved as {filename} in {directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model_v6.pkl in models\n"
     ]
    }
   ],
   "source": [
    "save_model(W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(directory='models'):\n",
    "    latest_version = get_latest_model_version(directory)\n",
    "    if latest_version == 0:\n",
    "        raise FileNotFoundError(\"No saved model found in the directory.\")\n",
    "\n",
    "    filename = f'model_v{latest_version}.pkl'\n",
    "    filepath = os.path.join(directory, filename)\n",
    "\n",
    "    with open(filepath, 'rb') as file:\n",
    "        model_params = pickle.load(file)\n",
    "        print(f\"Loaded model version {latest_version} from {filepath}\")\n",
    "        return model_params['W1'], model_params['b1'], model_params['W2'], model_params['b2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model version 4 from models\\model_v4.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "W1, b1, W2, b2 = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conitnue Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  0 Loss:  0.19205889744916207 Accuracy:  0.9459666666666666\n",
      "Iteration:  50\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  50 Loss:  0.192057709258842 Accuracy:  0.9459666666666666\n",
      "Iteration:  100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  100 Loss:  0.19205652159724862 Accuracy:  0.9459666666666666\n",
      "Iteration:  150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  150 Loss:  0.19205533427887203 Accuracy:  0.9459666666666666\n",
      "Iteration:  200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  200 Loss:  0.19205414656749592 Accuracy:  0.9459666666666666\n",
      "Iteration:  250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  250 Loss:  0.19205295879034 Accuracy:  0.9459666666666666\n",
      "Iteration:  300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  300 Loss:  0.19205177148247835 Accuracy:  0.9459833333333333\n",
      "Iteration:  350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  350 Loss:  0.19205058459786895 Accuracy:  0.9459833333333333\n",
      "Iteration:  400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  400 Loss:  0.19204939738525534 Accuracy:  0.9459833333333333\n",
      "Iteration:  450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  450 Loss:  0.19204821044180642 Accuracy:  0.9459833333333333\n",
      "Iteration:  500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  500 Loss:  0.19204702389141123 Accuracy:  0.946\n",
      "Iteration:  550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  550 Loss:  0.19204583799016958 Accuracy:  0.946\n",
      "Iteration:  600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  600 Loss:  0.19204465181256677 Accuracy:  0.946\n",
      "Iteration:  650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  650 Loss:  0.19204346540913 Accuracy:  0.946\n",
      "Iteration:  700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  700 Loss:  0.19204227973983654 Accuracy:  0.946\n",
      "Iteration:  750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  750 Loss:  0.1920410943167279 Accuracy:  0.946\n",
      "Iteration:  800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  800 Loss:  0.19203990876558188 Accuracy:  0.946\n",
      "Iteration:  850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  850 Loss:  0.19203872343383546 Accuracy:  0.946\n",
      "Iteration:  900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  900 Loss:  0.1920375382596782 Accuracy:  0.946\n",
      "Iteration:  950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  950 Loss:  0.19203635354669385 Accuracy:  0.946\n",
      "Iteration:  1000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1000 Loss:  0.19203516893377462 Accuracy:  0.946\n",
      "Iteration:  1050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1050 Loss:  0.19203398400572863 Accuracy:  0.946\n",
      "Iteration:  1100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1100 Loss:  0.19203279934884088 Accuracy:  0.946\n",
      "Iteration:  1150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1150 Loss:  0.1920316154371727 Accuracy:  0.946\n",
      "Iteration:  1200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1200 Loss:  0.19203043097723893 Accuracy:  0.946\n",
      "Iteration:  1250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1250 Loss:  0.19202924641300742 Accuracy:  0.946\n",
      "Iteration:  1300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1300 Loss:  0.1920280623465069 Accuracy:  0.946\n",
      "Iteration:  1350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1350 Loss:  0.19202687847646965 Accuracy:  0.946\n",
      "Iteration:  1400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1400 Loss:  0.1920256942910412 Accuracy:  0.946\n",
      "Iteration:  1450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1450 Loss:  0.19202451013796348 Accuracy:  0.946\n",
      "Iteration:  1500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1500 Loss:  0.19202332610636155 Accuracy:  0.946\n",
      "Iteration:  1550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1550 Loss:  0.19202214191702208 Accuracy:  0.946\n",
      "Iteration:  1600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1600 Loss:  0.19202095794096605 Accuracy:  0.946\n",
      "Iteration:  1650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1650 Loss:  0.1920197744711535 Accuracy:  0.946\n",
      "Iteration:  1700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1700 Loss:  0.19201859099110513 Accuracy:  0.946\n",
      "Iteration:  1750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1750 Loss:  0.192017407949145 Accuracy:  0.946\n",
      "Iteration:  1800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1800 Loss:  0.1920162245838331 Accuracy:  0.946\n",
      "Iteration:  1850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1850 Loss:  0.19201504150550067 Accuracy:  0.946\n",
      "Iteration:  1900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1900 Loss:  0.19201385731299128 Accuracy:  0.946\n",
      "Iteration:  1950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  1950 Loss:  0.19201267262455204 Accuracy:  0.946\n",
      "Iteration:  2000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2000 Loss:  0.19201148826408557 Accuracy:  0.946\n",
      "Iteration:  2050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2050 Loss:  0.19201030430499244 Accuracy:  0.946\n",
      "Iteration:  2100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2100 Loss:  0.1920091208709647 Accuracy:  0.946\n",
      "Iteration:  2150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2150 Loss:  0.19200793745857175 Accuracy:  0.946\n",
      "Iteration:  2200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2200 Loss:  0.19200675400724188 Accuracy:  0.946\n",
      "Iteration:  2250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2250 Loss:  0.1920055708160695 Accuracy:  0.946\n",
      "Iteration:  2300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2300 Loss:  0.19200438799781555 Accuracy:  0.946\n",
      "Iteration:  2350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2350 Loss:  0.1920032052400442 Accuracy:  0.946\n",
      "Iteration:  2400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2400 Loss:  0.1920020224446834 Accuracy:  0.946\n",
      "Iteration:  2450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2450 Loss:  0.19200084001151127 Accuracy:  0.946\n",
      "Iteration:  2500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2500 Loss:  0.1919996578692152 Accuracy:  0.946\n",
      "Iteration:  2550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2550 Loss:  0.19199847561290745 Accuracy:  0.946\n",
      "Iteration:  2600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2600 Loss:  0.19199729399862928 Accuracy:  0.946\n",
      "Iteration:  2650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2650 Loss:  0.1919961121672451 Accuracy:  0.946\n",
      "Iteration:  2700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2700 Loss:  0.19199493068032208 Accuracy:  0.946\n",
      "Iteration:  2750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2750 Loss:  0.19199374932753022 Accuracy:  0.946\n",
      "Iteration:  2800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2800 Loss:  0.19199256832521613 Accuracy:  0.946\n",
      "Iteration:  2850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2850 Loss:  0.19199138724115924 Accuracy:  0.946\n",
      "Iteration:  2900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2900 Loss:  0.1919902064454406 Accuracy:  0.946\n",
      "Iteration:  2950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  2950 Loss:  0.19198902567414028 Accuracy:  0.946\n",
      "Iteration:  3000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3000 Loss:  0.1919878455482916 Accuracy:  0.946\n",
      "Iteration:  3050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3050 Loss:  0.1919866647607998 Accuracy:  0.946\n",
      "Iteration:  3100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3100 Loss:  0.1919854845132398 Accuracy:  0.946\n",
      "Iteration:  3150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3150 Loss:  0.19198430437018646 Accuracy:  0.946\n",
      "Iteration:  3200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3200 Loss:  0.19198312475407156 Accuracy:  0.946\n",
      "Iteration:  3250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3250 Loss:  0.19198194497266238 Accuracy:  0.946\n",
      "Iteration:  3300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3300 Loss:  0.19198076530656263 Accuracy:  0.946\n",
      "Iteration:  3350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3350 Loss:  0.19197958583064037 Accuracy:  0.946\n",
      "Iteration:  3400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3400 Loss:  0.19197840648330056 Accuracy:  0.946\n",
      "Iteration:  3450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3450 Loss:  0.19197722736032602 Accuracy:  0.946\n",
      "Iteration:  3500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3500 Loss:  0.19197604840661422 Accuracy:  0.946\n",
      "Iteration:  3550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3550 Loss:  0.19197486947099346 Accuracy:  0.946\n",
      "Iteration:  3600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3600 Loss:  0.19197369106764284 Accuracy:  0.946\n",
      "Iteration:  3650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3650 Loss:  0.19197250920695125 Accuracy:  0.946\n",
      "Iteration:  3700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3700 Loss:  0.19197132553632337 Accuracy:  0.946\n",
      "Iteration:  3750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3750 Loss:  0.1919701418165267 Accuracy:  0.946\n",
      "Iteration:  3800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3800 Loss:  0.19196895840624187 Accuracy:  0.946\n",
      "Iteration:  3850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3850 Loss:  0.19196777512144633 Accuracy:  0.946\n",
      "Iteration:  3900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3900 Loss:  0.19196659268545588 Accuracy:  0.946\n",
      "Iteration:  3950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  3950 Loss:  0.19196541024769076 Accuracy:  0.946\n",
      "Iteration:  4000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4000 Loss:  0.19196422793428328 Accuracy:  0.946\n",
      "Iteration:  4050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4050 Loss:  0.19196304600912592 Accuracy:  0.946\n",
      "Iteration:  4100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4100 Loss:  0.19196186395456608 Accuracy:  0.946\n",
      "Iteration:  4150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4150 Loss:  0.191960680535994 Accuracy:  0.946\n",
      "Iteration:  4200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4200 Loss:  0.1919594943771072 Accuracy:  0.946\n",
      "Iteration:  4250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4250 Loss:  0.191958308255523 Accuracy:  0.946\n",
      "Iteration:  4300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4300 Loss:  0.19195712248087662 Accuracy:  0.946\n",
      "Iteration:  4350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4350 Loss:  0.19195593704585487 Accuracy:  0.946\n",
      "Iteration:  4400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4400 Loss:  0.1919547517838635 Accuracy:  0.946\n",
      "Iteration:  4450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4450 Loss:  0.1919535664807231 Accuracy:  0.946\n",
      "Iteration:  4500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4500 Loss:  0.19195238126662093 Accuracy:  0.946\n",
      "Iteration:  4550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4550 Loss:  0.19195119650851045 Accuracy:  0.946\n",
      "Iteration:  4600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4600 Loss:  0.1919500115979505 Accuracy:  0.946\n",
      "Iteration:  4650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4650 Loss:  0.19194882683007305 Accuracy:  0.946\n",
      "Iteration:  4700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4700 Loss:  0.1919476421806444 Accuracy:  0.946\n",
      "Iteration:  4750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4750 Loss:  0.19194645765790128 Accuracy:  0.946\n",
      "Iteration:  4800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4800 Loss:  0.19194527330595962 Accuracy:  0.946\n",
      "Iteration:  4850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4850 Loss:  0.1919440890416767 Accuracy:  0.946\n",
      "Iteration:  4900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4900 Loss:  0.19194290478926548 Accuracy:  0.946\n",
      "Iteration:  4950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  4950 Loss:  0.19194172101624954 Accuracy:  0.946\n",
      "Iteration:  5000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5000 Loss:  0.19194053662012805 Accuracy:  0.946\n",
      "Iteration:  5050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5050 Loss:  0.19193935286407793 Accuracy:  0.946\n",
      "Iteration:  5100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5100 Loss:  0.1919381694423822 Accuracy:  0.946\n",
      "Iteration:  5150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5150 Loss:  0.19193698587568667 Accuracy:  0.946\n",
      "Iteration:  5200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5200 Loss:  0.1919358028283879 Accuracy:  0.946\n",
      "Iteration:  5250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5250 Loss:  0.19193461970215084 Accuracy:  0.946\n",
      "Iteration:  5300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5300 Loss:  0.191933436768712 Accuracy:  0.946\n",
      "Iteration:  5350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5350 Loss:  0.19193225406807649 Accuracy:  0.9460166666666666\n",
      "Iteration:  5400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5400 Loss:  0.19193107163553824 Accuracy:  0.9460166666666666\n",
      "Iteration:  5450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5450 Loss:  0.19192988934404276 Accuracy:  0.9460166666666666\n",
      "Iteration:  5500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5500 Loss:  0.19192870725356515 Accuracy:  0.9460166666666666\n",
      "Iteration:  5550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5550 Loss:  0.19192752514933442 Accuracy:  0.9460166666666666\n",
      "Iteration:  5600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5600 Loss:  0.19192634358130095 Accuracy:  0.9460166666666666\n",
      "Iteration:  5650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5650 Loss:  0.1919251617649538 Accuracy:  0.9460166666666666\n",
      "Iteration:  5700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5700 Loss:  0.191923980454258 Accuracy:  0.9460166666666666\n",
      "Iteration:  5750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5750 Loss:  0.19192279958334613 Accuracy:  0.9460166666666666\n",
      "Iteration:  5800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5800 Loss:  0.19192161856894788 Accuracy:  0.9460333333333333\n",
      "Iteration:  5850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5850 Loss:  0.19192043769521033 Accuracy:  0.9460333333333333\n",
      "Iteration:  5900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5900 Loss:  0.1919192573326796 Accuracy:  0.9460333333333333\n",
      "Iteration:  5950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  5950 Loss:  0.19191807687705534 Accuracy:  0.9460333333333333\n",
      "Iteration:  6000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6000 Loss:  0.19191689673626539 Accuracy:  0.9460333333333333\n",
      "Iteration:  6050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6050 Loss:  0.1919157166917922 Accuracy:  0.9460333333333333\n",
      "Iteration:  6100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6100 Loss:  0.1919145367014499 Accuracy:  0.9460333333333333\n",
      "Iteration:  6150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6150 Loss:  0.19191335730514836 Accuracy:  0.9460333333333333\n",
      "Iteration:  6200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6200 Loss:  0.19191217819468517 Accuracy:  0.9460333333333333\n",
      "Iteration:  6250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6250 Loss:  0.1919109992679741 Accuracy:  0.9460333333333333\n",
      "Iteration:  6300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6300 Loss:  0.19190982032475312 Accuracy:  0.9460333333333333\n",
      "Iteration:  6350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6350 Loss:  0.19190864179810235 Accuracy:  0.9460333333333333\n",
      "Iteration:  6400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6400 Loss:  0.1919074631830409 Accuracy:  0.94605\n",
      "Iteration:  6450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6450 Loss:  0.19190628509143404 Accuracy:  0.9460666666666666\n",
      "Iteration:  6500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6500 Loss:  0.191905107095805 Accuracy:  0.9460666666666666\n",
      "Iteration:  6550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6550 Loss:  0.191903928878913 Accuracy:  0.9460666666666666\n",
      "Iteration:  6600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6600 Loss:  0.19190275114523625 Accuracy:  0.9460666666666666\n",
      "Iteration:  6650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6650 Loss:  0.1919015735601374 Accuracy:  0.9460666666666666\n",
      "Iteration:  6700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6700 Loss:  0.19190039619515242 Accuracy:  0.9460666666666666\n",
      "Iteration:  6750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6750 Loss:  0.19189921888188646 Accuracy:  0.9460666666666666\n",
      "Iteration:  6800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6800 Loss:  0.19189804183745024 Accuracy:  0.9460666666666666\n",
      "Iteration:  6850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6850 Loss:  0.1918968647304252 Accuracy:  0.9460666666666666\n",
      "Iteration:  6900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6900 Loss:  0.19189568810345556 Accuracy:  0.9460666666666666\n",
      "Iteration:  6950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  6950 Loss:  0.19189451136857694 Accuracy:  0.9460666666666666\n",
      "Iteration:  7000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7000 Loss:  0.19189333543206305 Accuracy:  0.9460666666666666\n",
      "Iteration:  7050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7050 Loss:  0.19189215886696032 Accuracy:  0.9460666666666666\n",
      "Iteration:  7100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7100 Loss:  0.19189098298085674 Accuracy:  0.9460666666666666\n",
      "Iteration:  7150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7150 Loss:  0.19188980685340898 Accuracy:  0.9460666666666666\n",
      "Iteration:  7200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7200 Loss:  0.19188863121918287 Accuracy:  0.9460666666666666\n",
      "Iteration:  7250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7250 Loss:  0.19188745559328427 Accuracy:  0.9460666666666666\n",
      "Iteration:  7300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7300 Loss:  0.1918862800975056 Accuracy:  0.9460666666666666\n",
      "Iteration:  7350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7350 Loss:  0.19188510478938406 Accuracy:  0.9460666666666666\n",
      "Iteration:  7400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7400 Loss:  0.1918839297570243 Accuracy:  0.9460666666666666\n",
      "Iteration:  7450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7450 Loss:  0.19188275496625498 Accuracy:  0.9460666666666666\n",
      "Iteration:  7500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7500 Loss:  0.19188158011664114 Accuracy:  0.9460666666666666\n",
      "Iteration:  7550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7550 Loss:  0.19188040571965706 Accuracy:  0.9460666666666666\n",
      "Iteration:  7600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7600 Loss:  0.19187923130753032 Accuracy:  0.9460666666666666\n",
      "Iteration:  7650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7650 Loss:  0.19187805672220817 Accuracy:  0.94605\n",
      "Iteration:  7700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7700 Loss:  0.19187688271458792 Accuracy:  0.9460666666666666\n",
      "Iteration:  7750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7750 Loss:  0.19187570916944807 Accuracy:  0.9460666666666666\n",
      "Iteration:  7800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7800 Loss:  0.19187453549147576 Accuracy:  0.9460666666666666\n",
      "Iteration:  7850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7850 Loss:  0.1918733615602922 Accuracy:  0.9460666666666666\n",
      "Iteration:  7900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7900 Loss:  0.19187218775084755 Accuracy:  0.9460666666666666\n",
      "Iteration:  7950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  7950 Loss:  0.19187101407990134 Accuracy:  0.9460666666666666\n",
      "Iteration:  8000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8000 Loss:  0.19186984050629055 Accuracy:  0.9460666666666666\n",
      "Iteration:  8050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8050 Loss:  0.1918686670714088 Accuracy:  0.94605\n",
      "Iteration:  8100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8100 Loss:  0.19186749392119484 Accuracy:  0.94605\n",
      "Iteration:  8150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8150 Loss:  0.19186632093209707 Accuracy:  0.94605\n",
      "Iteration:  8200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8200 Loss:  0.19186514815763422 Accuracy:  0.94605\n",
      "Iteration:  8250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8250 Loss:  0.19186397555771179 Accuracy:  0.94605\n",
      "Iteration:  8300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8300 Loss:  0.19186280294396685 Accuracy:  0.94605\n",
      "Iteration:  8350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8350 Loss:  0.19186163058565822 Accuracy:  0.94605\n",
      "Iteration:  8400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8400 Loss:  0.19186045827401782 Accuracy:  0.94605\n",
      "Iteration:  8450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8450 Loss:  0.1918592863316459 Accuracy:  0.94605\n",
      "Iteration:  8500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8500 Loss:  0.19185811432761135 Accuracy:  0.94605\n",
      "Iteration:  8550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8550 Loss:  0.19185694285848667 Accuracy:  0.94605\n",
      "Iteration:  8600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8600 Loss:  0.19185577158647213 Accuracy:  0.94605\n",
      "Iteration:  8650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8650 Loss:  0.19185460035245738 Accuracy:  0.94605\n",
      "Iteration:  8700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8700 Loss:  0.19185342935387764 Accuracy:  0.94605\n",
      "Iteration:  8750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8750 Loss:  0.19185225861493121 Accuracy:  0.94605\n",
      "Iteration:  8800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8800 Loss:  0.19185108808539256 Accuracy:  0.94605\n",
      "Iteration:  8850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8850 Loss:  0.1918499173927272 Accuracy:  0.94605\n",
      "Iteration:  8900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8900 Loss:  0.19184874714219152 Accuracy:  0.94605\n",
      "Iteration:  8950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  8950 Loss:  0.19184757725958662 Accuracy:  0.94605\n",
      "Iteration:  9000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9000 Loss:  0.1918464073522761 Accuracy:  0.94605\n",
      "Iteration:  9050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9050 Loss:  0.19184523828721345 Accuracy:  0.94605\n",
      "Iteration:  9100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9100 Loss:  0.19184406835911014 Accuracy:  0.94605\n",
      "Iteration:  9150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9150 Loss:  0.19184289878367053 Accuracy:  0.94605\n",
      "Iteration:  9200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9200 Loss:  0.1918417298086113 Accuracy:  0.94605\n",
      "Iteration:  9250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9250 Loss:  0.19184056093299584 Accuracy:  0.94605\n",
      "Iteration:  9300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9300 Loss:  0.19183939239732697 Accuracy:  0.94605\n",
      "Iteration:  9350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9350 Loss:  0.1918382239599005 Accuracy:  0.94605\n",
      "Iteration:  9400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9400 Loss:  0.19183705543366283 Accuracy:  0.94605\n",
      "Iteration:  9450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9450 Loss:  0.19183588713454686 Accuracy:  0.9460333333333333\n",
      "Iteration:  9500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9500 Loss:  0.19183471863216162 Accuracy:  0.9460333333333333\n",
      "Iteration:  9550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9550 Loss:  0.19183354905322636 Accuracy:  0.9460333333333333\n",
      "Iteration:  9600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9600 Loss:  0.19183237998053548 Accuracy:  0.9460333333333333\n",
      "Iteration:  9650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9650 Loss:  0.19183121042226228 Accuracy:  0.9460333333333333\n",
      "Iteration:  9700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9700 Loss:  0.19183004146005303 Accuracy:  0.9460333333333333\n",
      "Iteration:  9750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9750 Loss:  0.19182887247629646 Accuracy:  0.9460333333333333\n",
      "Iteration:  9800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9800 Loss:  0.19182770366299828 Accuracy:  0.9460333333333333\n",
      "Iteration:  9850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9850 Loss:  0.19182653498389102 Accuracy:  0.9460333333333333\n",
      "Iteration:  9900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9900 Loss:  0.19182536644405235 Accuracy:  0.9460333333333333\n",
      "Iteration:  9950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  9950 Loss:  0.19182419798462322 Accuracy:  0.9460333333333333\n",
      "Iteration:  10000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10000 Loss:  0.191823029683757 Accuracy:  0.9460333333333333\n",
      "Iteration:  10050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10050 Loss:  0.19182186170424131 Accuracy:  0.9460333333333333\n",
      "Iteration:  10100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10100 Loss:  0.1918206939409747 Accuracy:  0.9460333333333333\n",
      "Iteration:  10150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10150 Loss:  0.19181952513038295 Accuracy:  0.9460333333333333\n",
      "Iteration:  10200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10200 Loss:  0.19181835631349384 Accuracy:  0.9460333333333333\n",
      "Iteration:  10250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10250 Loss:  0.19181718761023853 Accuracy:  0.9460333333333333\n",
      "Iteration:  10300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10300 Loss:  0.19181601933092976 Accuracy:  0.9460333333333333\n",
      "Iteration:  10350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10350 Loss:  0.1918148510833443 Accuracy:  0.9460333333333333\n",
      "Iteration:  10400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10400 Loss:  0.19181368304761645 Accuracy:  0.9460333333333333\n",
      "Iteration:  10450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10450 Loss:  0.19181251413620223 Accuracy:  0.9460333333333333\n",
      "Iteration:  10500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10500 Loss:  0.19181134474771086 Accuracy:  0.94605\n",
      "Iteration:  10550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10550 Loss:  0.1918101756528541 Accuracy:  0.94605\n",
      "Iteration:  10600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10600 Loss:  0.19180900668351142 Accuracy:  0.94605\n",
      "Iteration:  10650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10650 Loss:  0.19180783759281742 Accuracy:  0.94605\n",
      "Iteration:  10700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10700 Loss:  0.1918066671245538 Accuracy:  0.94605\n",
      "Iteration:  10750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10750 Loss:  0.19180549675052713 Accuracy:  0.94605\n",
      "Iteration:  10800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10800 Loss:  0.1918043269971421 Accuracy:  0.94605\n",
      "Iteration:  10850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10850 Loss:  0.19180315716267723 Accuracy:  0.94605\n",
      "Iteration:  10900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10900 Loss:  0.1918019876867022 Accuracy:  0.94605\n",
      "Iteration:  10950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10950 Loss:  0.19180081864492207 Accuracy:  0.94605\n",
      "Iteration:  11000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11000 Loss:  0.1917996497492416 Accuracy:  0.94605\n",
      "Iteration:  11050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11050 Loss:  0.19179848027057805 Accuracy:  0.94605\n",
      "Iteration:  11100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11100 Loss:  0.19179731132808883 Accuracy:  0.94605\n",
      "Iteration:  11150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11150 Loss:  0.19179614279793109 Accuracy:  0.94605\n",
      "Iteration:  11200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11200 Loss:  0.1917949742980541 Accuracy:  0.9460666666666666\n",
      "Iteration:  11250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11250 Loss:  0.19179380588596132 Accuracy:  0.9460666666666666\n",
      "Iteration:  11300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11300 Loss:  0.19179263795947968 Accuracy:  0.9460666666666666\n",
      "Iteration:  11350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11350 Loss:  0.19179147005619746 Accuracy:  0.9460666666666666\n",
      "Iteration:  11400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11400 Loss:  0.19179030212398177 Accuracy:  0.9460666666666666\n",
      "Iteration:  11450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11450 Loss:  0.1917891349380385 Accuracy:  0.9460666666666666\n",
      "Iteration:  11500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11500 Loss:  0.19178796703646267 Accuracy:  0.9460666666666666\n",
      "Iteration:  11550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11550 Loss:  0.1917867999360173 Accuracy:  0.9460666666666666\n",
      "Iteration:  11600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11600 Loss:  0.19178563275958924 Accuracy:  0.9460666666666666\n",
      "Iteration:  11650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11650 Loss:  0.19178446566916027 Accuracy:  0.9460666666666666\n",
      "Iteration:  11700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11700 Loss:  0.19178329891528184 Accuracy:  0.94605\n",
      "Iteration:  11750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11750 Loss:  0.19178213214728504 Accuracy:  0.94605\n",
      "Iteration:  11800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11800 Loss:  0.1917809658120438 Accuracy:  0.94605\n",
      "Iteration:  11850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11850 Loss:  0.19177979928691039 Accuracy:  0.94605\n",
      "Iteration:  11900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11900 Loss:  0.19177863295869108 Accuracy:  0.94605\n",
      "Iteration:  11950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  11950 Loss:  0.19177746701803272 Accuracy:  0.94605\n",
      "Iteration:  12000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12000 Loss:  0.19177630059984838 Accuracy:  0.94605\n",
      "Iteration:  12050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12050 Loss:  0.19177513449756595 Accuracy:  0.94605\n",
      "Iteration:  12100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12100 Loss:  0.19177396908307687 Accuracy:  0.94605\n",
      "Iteration:  12150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12150 Loss:  0.19177280283756679 Accuracy:  0.9460333333333333\n",
      "Iteration:  12200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12200 Loss:  0.19177163738197814 Accuracy:  0.9460333333333333\n",
      "Iteration:  12250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12250 Loss:  0.19177047187747023 Accuracy:  0.9460333333333333\n",
      "Iteration:  12300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12300 Loss:  0.19176930679498863 Accuracy:  0.9460333333333333\n",
      "Iteration:  12350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12350 Loss:  0.19176813988534616 Accuracy:  0.9460333333333333\n",
      "Iteration:  12400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12400 Loss:  0.19176697148261485 Accuracy:  0.9460333333333333\n",
      "Iteration:  12450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12450 Loss:  0.191765803311553 Accuracy:  0.9460333333333333\n",
      "Iteration:  12500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12500 Loss:  0.19176463540883787 Accuracy:  0.9460333333333333\n",
      "Iteration:  12550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12550 Loss:  0.19176346766515726 Accuracy:  0.9460333333333333\n",
      "Iteration:  12600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12600 Loss:  0.19176230022276056 Accuracy:  0.9460333333333333\n",
      "Iteration:  12650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12650 Loss:  0.19176113261169436 Accuracy:  0.9460333333333333\n",
      "Iteration:  12700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12700 Loss:  0.19175996551085148 Accuracy:  0.9460333333333333\n",
      "Iteration:  12750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12750 Loss:  0.19175879838454735 Accuracy:  0.9460333333333333\n",
      "Iteration:  12800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12800 Loss:  0.19175763144599212 Accuracy:  0.9460333333333333\n",
      "Iteration:  12850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12850 Loss:  0.1917564650764056 Accuracy:  0.9460333333333333\n",
      "Iteration:  12900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12900 Loss:  0.19175529862368063 Accuracy:  0.9460333333333333\n",
      "Iteration:  12950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  12950 Loss:  0.191754132476091 Accuracy:  0.9460333333333333\n",
      "Iteration:  13000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13000 Loss:  0.19175296648473603 Accuracy:  0.9460333333333333\n",
      "Iteration:  13050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13050 Loss:  0.19175180057225807 Accuracy:  0.9460333333333333\n",
      "Iteration:  13100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13100 Loss:  0.19175063501614323 Accuracy:  0.9460333333333333\n",
      "Iteration:  13150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13150 Loss:  0.19174946950303037 Accuracy:  0.9460333333333333\n",
      "Iteration:  13200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13200 Loss:  0.19174830421986683 Accuracy:  0.94605\n",
      "Iteration:  13250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13250 Loss:  0.19174713874047578 Accuracy:  0.94605\n",
      "Iteration:  13300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13300 Loss:  0.19174597363472864 Accuracy:  0.94605\n",
      "Iteration:  13350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13350 Loss:  0.19174480884178086 Accuracy:  0.94605\n",
      "Iteration:  13400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13400 Loss:  0.19174364399355148 Accuracy:  0.94605\n",
      "Iteration:  13450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13450 Loss:  0.19174247917362533 Accuracy:  0.94605\n",
      "Iteration:  13500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13500 Loss:  0.19174131464329017 Accuracy:  0.94605\n",
      "Iteration:  13550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13550 Loss:  0.19174014984938598 Accuracy:  0.94605\n",
      "Iteration:  13600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13600 Loss:  0.19173898471031714 Accuracy:  0.94605\n",
      "Iteration:  13650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13650 Loss:  0.19173781987080152 Accuracy:  0.94605\n",
      "Iteration:  13700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13700 Loss:  0.19173665517402086 Accuracy:  0.94605\n",
      "Iteration:  13750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13750 Loss:  0.19173549029905065 Accuracy:  0.94605\n",
      "Iteration:  13800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13800 Loss:  0.19173432586587855 Accuracy:  0.94605\n",
      "Iteration:  13850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13850 Loss:  0.19173316117276548 Accuracy:  0.94605\n",
      "Iteration:  13900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13900 Loss:  0.19173199683127756 Accuracy:  0.94605\n",
      "Iteration:  13950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  13950 Loss:  0.1917308321808478 Accuracy:  0.94605\n",
      "Iteration:  14000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14000 Loss:  0.19172966800584768 Accuracy:  0.94605\n",
      "Iteration:  14050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14050 Loss:  0.19172850424389096 Accuracy:  0.94605\n",
      "Iteration:  14100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14100 Loss:  0.19172733995625876 Accuracy:  0.94605\n",
      "Iteration:  14150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14150 Loss:  0.19172617608970877 Accuracy:  0.94605\n",
      "Iteration:  14200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14200 Loss:  0.19172501256871663 Accuracy:  0.94605\n",
      "Iteration:  14250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14250 Loss:  0.19172384903281658 Accuracy:  0.94605\n",
      "Iteration:  14300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14300 Loss:  0.19172268589539318 Accuracy:  0.94605\n",
      "Iteration:  14350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14350 Loss:  0.1917215227417319 Accuracy:  0.94605\n",
      "Iteration:  14400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14400 Loss:  0.1917203599431095 Accuracy:  0.94605\n",
      "Iteration:  14450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14450 Loss:  0.19171919697894643 Accuracy:  0.94605\n",
      "Iteration:  14500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14500 Loss:  0.19171803446883648 Accuracy:  0.94605\n",
      "Iteration:  14550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14550 Loss:  0.19171687212385385 Accuracy:  0.94605\n",
      "Iteration:  14600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14600 Loss:  0.19171570978673763 Accuracy:  0.94605\n",
      "Iteration:  14650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14650 Loss:  0.1917145477207873 Accuracy:  0.94605\n",
      "Iteration:  14700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14700 Loss:  0.19171338593049558 Accuracy:  0.94605\n",
      "Iteration:  14750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14750 Loss:  0.19171222381738662 Accuracy:  0.94605\n",
      "Iteration:  14800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14800 Loss:  0.1917110620590009 Accuracy:  0.94605\n",
      "Iteration:  14850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14850 Loss:  0.19170990014775047 Accuracy:  0.94605\n",
      "Iteration:  14900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14900 Loss:  0.19170873864496407 Accuracy:  0.94605\n",
      "Iteration:  14950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  14950 Loss:  0.19170757714259282 Accuracy:  0.94605\n",
      "Iteration:  15000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15000 Loss:  0.1917064159287902 Accuracy:  0.94605\n",
      "Iteration:  15050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15050 Loss:  0.19170525444129502 Accuracy:  0.94605\n",
      "Iteration:  15100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15100 Loss:  0.19170409286409548 Accuracy:  0.94605\n",
      "Iteration:  15150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15150 Loss:  0.1917029314164635 Accuracy:  0.94605\n",
      "Iteration:  15200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15200 Loss:  0.19170177019424892 Accuracy:  0.94605\n",
      "Iteration:  15250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15250 Loss:  0.19170060903136366 Accuracy:  0.94605\n",
      "Iteration:  15300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15300 Loss:  0.19169944842784592 Accuracy:  0.94605\n",
      "Iteration:  15350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15350 Loss:  0.19169828805812436 Accuracy:  0.94605\n",
      "Iteration:  15400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15400 Loss:  0.19169712782350212 Accuracy:  0.94605\n",
      "Iteration:  15450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15450 Loss:  0.1916959678806237 Accuracy:  0.94605\n",
      "Iteration:  15500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15500 Loss:  0.1916948078519299 Accuracy:  0.94605\n",
      "Iteration:  15550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15550 Loss:  0.1916936480800164 Accuracy:  0.94605\n",
      "Iteration:  15600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15600 Loss:  0.19169248851364815 Accuracy:  0.94605\n",
      "Iteration:  15650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15650 Loss:  0.19169132910262096 Accuracy:  0.94605\n",
      "Iteration:  15700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15700 Loss:  0.19169016989040227 Accuracy:  0.94605\n",
      "Iteration:  15750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15750 Loss:  0.19168900991119683 Accuracy:  0.94605\n",
      "Iteration:  15800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15800 Loss:  0.19168784993179036 Accuracy:  0.94605\n",
      "Iteration:  15850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15850 Loss:  0.19168669003554273 Accuracy:  0.94605\n",
      "Iteration:  15900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15900 Loss:  0.19168553056280335 Accuracy:  0.94605\n",
      "Iteration:  15950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  15950 Loss:  0.19168437078918626 Accuracy:  0.94605\n",
      "Iteration:  16000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16000 Loss:  0.19168321120914072 Accuracy:  0.94605\n",
      "Iteration:  16050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16050 Loss:  0.1916820521282624 Accuracy:  0.94605\n",
      "Iteration:  16100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16100 Loss:  0.19168089292264953 Accuracy:  0.94605\n",
      "Iteration:  16150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16150 Loss:  0.1916797339644544 Accuracy:  0.94605\n",
      "Iteration:  16200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16200 Loss:  0.1916785754272503 Accuracy:  0.94605\n",
      "Iteration:  16250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16250 Loss:  0.19167741633651225 Accuracy:  0.94605\n",
      "Iteration:  16300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16300 Loss:  0.1916762578102216 Accuracy:  0.94605\n",
      "Iteration:  16350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16350 Loss:  0.1916750995266593 Accuracy:  0.94605\n",
      "Iteration:  16400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16400 Loss:  0.19167394127497125 Accuracy:  0.94605\n",
      "Iteration:  16450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16450 Loss:  0.19167278324431047 Accuracy:  0.9460833333333334\n",
      "Iteration:  16500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16500 Loss:  0.1916716250548276 Accuracy:  0.9460833333333334\n",
      "Iteration:  16550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16550 Loss:  0.19167046716062994 Accuracy:  0.9460833333333334\n",
      "Iteration:  16600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16600 Loss:  0.19166930950521918 Accuracy:  0.9460833333333334\n",
      "Iteration:  16650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16650 Loss:  0.19166815219992747 Accuracy:  0.9460833333333334\n",
      "Iteration:  16700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16700 Loss:  0.19166699519013916 Accuracy:  0.9460833333333334\n",
      "Iteration:  16750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16750 Loss:  0.191665838656432 Accuracy:  0.9460833333333334\n",
      "Iteration:  16800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16800 Loss:  0.19166468206138715 Accuracy:  0.9460833333333334\n",
      "Iteration:  16850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16850 Loss:  0.1916635256999888 Accuracy:  0.9460833333333334\n",
      "Iteration:  16900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16900 Loss:  0.19166236940351283 Accuracy:  0.9460833333333334\n",
      "Iteration:  16950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  16950 Loss:  0.1916612133702013 Accuracy:  0.9460833333333334\n",
      "Iteration:  17000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17000 Loss:  0.19166005739905334 Accuracy:  0.9460833333333334\n",
      "Iteration:  17050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17050 Loss:  0.1916589015645806 Accuracy:  0.9460833333333334\n",
      "Iteration:  17100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17100 Loss:  0.19165774608746103 Accuracy:  0.9460666666666666\n",
      "Iteration:  17150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17150 Loss:  0.19165659048623937 Accuracy:  0.9460666666666666\n",
      "Iteration:  17200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17200 Loss:  0.1916554350618497 Accuracy:  0.9460666666666666\n",
      "Iteration:  17250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17250 Loss:  0.19165427955238687 Accuracy:  0.9460666666666666\n",
      "Iteration:  17300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17300 Loss:  0.1916531242335678 Accuracy:  0.9460666666666666\n",
      "Iteration:  17350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17350 Loss:  0.19165196887854444 Accuracy:  0.9460666666666666\n",
      "Iteration:  17400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17400 Loss:  0.1916508134886074 Accuracy:  0.9460666666666666\n",
      "Iteration:  17450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17450 Loss:  0.19164965840604137 Accuracy:  0.9460666666666666\n",
      "Iteration:  17500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17500 Loss:  0.19164850366960007 Accuracy:  0.9460666666666666\n",
      "Iteration:  17550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17550 Loss:  0.19164734867665137 Accuracy:  0.9460666666666666\n",
      "Iteration:  17600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17600 Loss:  0.1916461942236145 Accuracy:  0.9460666666666666\n",
      "Iteration:  17650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17650 Loss:  0.19164503959369703 Accuracy:  0.9460666666666666\n",
      "Iteration:  17700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17700 Loss:  0.19164388522402448 Accuracy:  0.9460666666666666\n",
      "Iteration:  17750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17750 Loss:  0.1916427311812469 Accuracy:  0.9460666666666666\n",
      "Iteration:  17800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17800 Loss:  0.1916415770534789 Accuracy:  0.9460666666666666\n",
      "Iteration:  17850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17850 Loss:  0.19164042330835507 Accuracy:  0.9460666666666666\n",
      "Iteration:  17900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17900 Loss:  0.19163926957781718 Accuracy:  0.9460666666666666\n",
      "Iteration:  17950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  17950 Loss:  0.19163811445642667 Accuracy:  0.9460666666666666\n",
      "Iteration:  18000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18000 Loss:  0.19163695951055554 Accuracy:  0.9460666666666666\n",
      "Iteration:  18050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18050 Loss:  0.1916358046073219 Accuracy:  0.9460666666666666\n",
      "Iteration:  18100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18100 Loss:  0.19163465004444397 Accuracy:  0.9460666666666666\n",
      "Iteration:  18150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18150 Loss:  0.19163349566783613 Accuracy:  0.9460666666666666\n",
      "Iteration:  18200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18200 Loss:  0.1916323405563989 Accuracy:  0.9460833333333334\n",
      "Iteration:  18250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18250 Loss:  0.19163118598291343 Accuracy:  0.9460833333333334\n",
      "Iteration:  18300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18300 Loss:  0.19163003168832052 Accuracy:  0.9460833333333334\n",
      "Iteration:  18350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18350 Loss:  0.19162887750885166 Accuracy:  0.9460833333333334\n",
      "Iteration:  18400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18400 Loss:  0.19162772229810413 Accuracy:  0.9460833333333334\n",
      "Iteration:  18450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18450 Loss:  0.19162656720405524 Accuracy:  0.9460833333333334\n",
      "Iteration:  18500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18500 Loss:  0.19162541199139935 Accuracy:  0.9460833333333334\n",
      "Iteration:  18550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18550 Loss:  0.1916242570099014 Accuracy:  0.9460833333333334\n",
      "Iteration:  18600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18600 Loss:  0.19162310220985004 Accuracy:  0.9461\n",
      "Iteration:  18650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18650 Loss:  0.1916219475662429 Accuracy:  0.9461\n",
      "Iteration:  18700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18700 Loss:  0.19162079283547473 Accuracy:  0.9461\n",
      "Iteration:  18750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18750 Loss:  0.19161963845263222 Accuracy:  0.9461\n",
      "Iteration:  18800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18800 Loss:  0.19161848424950095 Accuracy:  0.9461\n",
      "Iteration:  18850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18850 Loss:  0.19161733007953172 Accuracy:  0.9461\n",
      "Iteration:  18900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18900 Loss:  0.19161617607972709 Accuracy:  0.9461\n",
      "Iteration:  18950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  18950 Loss:  0.1916150221810487 Accuracy:  0.9461\n",
      "Iteration:  19000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19000 Loss:  0.1916138686663287 Accuracy:  0.9461\n",
      "Iteration:  19050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19050 Loss:  0.1916127155905604 Accuracy:  0.9461\n",
      "Iteration:  19100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19100 Loss:  0.19161156213445646 Accuracy:  0.9461\n",
      "Iteration:  19150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19150 Loss:  0.1916104091738833 Accuracy:  0.9461\n",
      "Iteration:  19200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19200 Loss:  0.19160925351973873 Accuracy:  0.9461\n",
      "Iteration:  19250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19250 Loss:  0.19160809810698173 Accuracy:  0.9461\n",
      "Iteration:  19300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19300 Loss:  0.1916069429006306 Accuracy:  0.9461\n",
      "Iteration:  19350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19350 Loss:  0.19160578782522972 Accuracy:  0.9461\n",
      "Iteration:  19400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19400 Loss:  0.1916046329180523 Accuracy:  0.9461\n",
      "Iteration:  19450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19450 Loss:  0.19160347827120158 Accuracy:  0.9461\n",
      "Iteration:  19500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19500 Loss:  0.1916023237012558 Accuracy:  0.9461\n",
      "Iteration:  19550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19550 Loss:  0.1916011693536718 Accuracy:  0.9461\n",
      "Iteration:  19600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19600 Loss:  0.1916000151291782 Accuracy:  0.9461\n",
      "Iteration:  19650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19650 Loss:  0.1915988613707433 Accuracy:  0.9461\n",
      "Iteration:  19700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19700 Loss:  0.1915977082918207 Accuracy:  0.9461\n",
      "Iteration:  19750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19750 Loss:  0.19159655535402464 Accuracy:  0.9461\n",
      "Iteration:  19800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19800 Loss:  0.1915954028492559 Accuracy:  0.9461\n",
      "Iteration:  19850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19850 Loss:  0.1915942503013172 Accuracy:  0.9461\n",
      "Iteration:  19900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19900 Loss:  0.1915930981175125 Accuracy:  0.9461\n",
      "Iteration:  19950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  19950 Loss:  0.19159194588876344 Accuracy:  0.9461\n",
      "Iteration:  20000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20000 Loss:  0.19159079396423184 Accuracy:  0.9461\n",
      "Iteration:  20050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20050 Loss:  0.19158964186502342 Accuracy:  0.9461\n",
      "Iteration:  20100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20100 Loss:  0.1915884900878156 Accuracy:  0.9461\n",
      "Iteration:  20150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20150 Loss:  0.19158733885537438 Accuracy:  0.9461\n",
      "Iteration:  20200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20200 Loss:  0.19158618718150588 Accuracy:  0.9461\n",
      "Iteration:  20250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20250 Loss:  0.19158503593396126 Accuracy:  0.9461\n",
      "Iteration:  20300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20300 Loss:  0.19158388471079527 Accuracy:  0.9461\n",
      "Iteration:  20350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20350 Loss:  0.19158273450036 Accuracy:  0.9461\n",
      "Iteration:  20400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20400 Loss:  0.1915815840398608 Accuracy:  0.9461\n",
      "Iteration:  20450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20450 Loss:  0.19158043480149775 Accuracy:  0.9461166666666667\n",
      "Iteration:  20500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20500 Loss:  0.19157928574318142 Accuracy:  0.9461166666666667\n",
      "Iteration:  20550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20550 Loss:  0.1915781363514915 Accuracy:  0.9461166666666667\n",
      "Iteration:  20600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20600 Loss:  0.19157698724701405 Accuracy:  0.9461166666666667\n",
      "Iteration:  20650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20650 Loss:  0.1915758381812719 Accuracy:  0.9461166666666667\n",
      "Iteration:  20700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20700 Loss:  0.19157468918196766 Accuracy:  0.9461166666666667\n",
      "Iteration:  20750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20750 Loss:  0.19157354075441693 Accuracy:  0.9461166666666667\n",
      "Iteration:  20800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20800 Loss:  0.19157239247944632 Accuracy:  0.9461166666666667\n",
      "Iteration:  20850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20850 Loss:  0.19157124457364952 Accuracy:  0.9461166666666667\n",
      "Iteration:  20900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20900 Loss:  0.1915700966145778 Accuracy:  0.9461166666666667\n",
      "Iteration:  20950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20950 Loss:  0.19156894883917097 Accuracy:  0.9461166666666667\n",
      "Iteration:  21000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21000 Loss:  0.19156780133207552 Accuracy:  0.9461166666666667\n",
      "Iteration:  21050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21050 Loss:  0.1915666539402481 Accuracy:  0.9461166666666667\n",
      "Iteration:  21100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21100 Loss:  0.1915655065739302 Accuracy:  0.9461166666666667\n",
      "Iteration:  21150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21150 Loss:  0.19156435940069905 Accuracy:  0.9461166666666667\n",
      "Iteration:  21200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21200 Loss:  0.19156321262620077 Accuracy:  0.9461166666666667\n",
      "Iteration:  21250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21250 Loss:  0.19156206592866531 Accuracy:  0.9461166666666667\n",
      "Iteration:  21300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21300 Loss:  0.19156091949744178 Accuracy:  0.9461166666666667\n",
      "Iteration:  21350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21350 Loss:  0.19155977315674158 Accuracy:  0.9461166666666667\n",
      "Iteration:  21400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21400 Loss:  0.19155862685369693 Accuracy:  0.9461166666666667\n",
      "Iteration:  21450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21450 Loss:  0.19155748087366467 Accuracy:  0.9461166666666667\n",
      "Iteration:  21500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21500 Loss:  0.19155633489967652 Accuracy:  0.9461166666666667\n",
      "Iteration:  21550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21550 Loss:  0.1915551889446004 Accuracy:  0.9461166666666667\n",
      "Iteration:  21600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21600 Loss:  0.19155404328359793 Accuracy:  0.9461166666666667\n",
      "Iteration:  21650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21650 Loss:  0.19155289674985024 Accuracy:  0.9461166666666667\n",
      "Iteration:  21700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21700 Loss:  0.19155174946161604 Accuracy:  0.9461166666666667\n",
      "Iteration:  21750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21750 Loss:  0.19155060218397457 Accuracy:  0.9461166666666667\n",
      "Iteration:  21800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21800 Loss:  0.19154945513110502 Accuracy:  0.9461166666666667\n",
      "Iteration:  21850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21850 Loss:  0.1915483081127708 Accuracy:  0.9461166666666667\n",
      "Iteration:  21900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21900 Loss:  0.19154716124533677 Accuracy:  0.9461166666666667\n",
      "Iteration:  21950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  21950 Loss:  0.19154601455958611 Accuracy:  0.9461166666666667\n",
      "Iteration:  22000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22000 Loss:  0.19154486803024126 Accuracy:  0.9461166666666667\n",
      "Iteration:  22050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22050 Loss:  0.19154372162835098 Accuracy:  0.9461166666666667\n",
      "Iteration:  22100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22100 Loss:  0.19154257510744294 Accuracy:  0.9461166666666667\n",
      "Iteration:  22150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22150 Loss:  0.191541428993638 Accuracy:  0.9461166666666667\n",
      "Iteration:  22200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22200 Loss:  0.1915402829988061 Accuracy:  0.9461166666666667\n",
      "Iteration:  22250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22250 Loss:  0.19153913656540933 Accuracy:  0.9461166666666667\n",
      "Iteration:  22300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22300 Loss:  0.1915379894425925 Accuracy:  0.9461166666666667\n",
      "Iteration:  22350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22350 Loss:  0.1915368424800645 Accuracy:  0.9461166666666667\n",
      "Iteration:  22400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22400 Loss:  0.19153569569649942 Accuracy:  0.9461333333333334\n",
      "Iteration:  22450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22450 Loss:  0.19153454908863665 Accuracy:  0.9461333333333334\n",
      "Iteration:  22500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22500 Loss:  0.19153340246630307 Accuracy:  0.9461333333333334\n",
      "Iteration:  22550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22550 Loss:  0.19153225605768748 Accuracy:  0.9461333333333334\n",
      "Iteration:  22600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22600 Loss:  0.19153110987211855 Accuracy:  0.9461333333333334\n",
      "Iteration:  22650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22650 Loss:  0.19152996379309764 Accuracy:  0.9461333333333334\n",
      "Iteration:  22700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22700 Loss:  0.19152881553139042 Accuracy:  0.9461333333333334\n",
      "Iteration:  22750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22750 Loss:  0.19152766747895525 Accuracy:  0.9461333333333334\n",
      "Iteration:  22800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22800 Loss:  0.1915265195802252 Accuracy:  0.9461333333333334\n",
      "Iteration:  22850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22850 Loss:  0.1915253717199795 Accuracy:  0.9461333333333334\n",
      "Iteration:  22900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22900 Loss:  0.19152422420827556 Accuracy:  0.9461333333333334\n",
      "Iteration:  22950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  22950 Loss:  0.1915230766897859 Accuracy:  0.9461333333333334\n",
      "Iteration:  23000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23000 Loss:  0.19152192950664743 Accuracy:  0.9461333333333334\n",
      "Iteration:  23050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23050 Loss:  0.19152078238922174 Accuracy:  0.9461333333333334\n",
      "Iteration:  23100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23100 Loss:  0.19151963544336717 Accuracy:  0.9461333333333334\n",
      "Iteration:  23150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23150 Loss:  0.1915184889887933 Accuracy:  0.9461333333333334\n",
      "Iteration:  23200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23200 Loss:  0.19151734308562512 Accuracy:  0.9461333333333334\n",
      "Iteration:  23250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23250 Loss:  0.19151619740060416 Accuracy:  0.9461333333333334\n",
      "Iteration:  23300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23300 Loss:  0.1915150519571042 Accuracy:  0.9461333333333334\n",
      "Iteration:  23350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23350 Loss:  0.19151390635600185 Accuracy:  0.9461333333333334\n",
      "Iteration:  23400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23400 Loss:  0.19151276127478914 Accuracy:  0.9461333333333334\n",
      "Iteration:  23450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23450 Loss:  0.19151161619499035 Accuracy:  0.94615\n",
      "Iteration:  23500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23500 Loss:  0.19151046759628132 Accuracy:  0.94615\n",
      "Iteration:  23550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23550 Loss:  0.19150931011138356 Accuracy:  0.94615\n",
      "Iteration:  23600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23600 Loss:  0.1915081530838316 Accuracy:  0.94615\n",
      "Iteration:  23650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23650 Loss:  0.1915069962931457 Accuracy:  0.94615\n",
      "Iteration:  23700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23700 Loss:  0.1915058397980096 Accuracy:  0.94615\n",
      "Iteration:  23750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23750 Loss:  0.19150468350712652 Accuracy:  0.94615\n",
      "Iteration:  23800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23800 Loss:  0.1915035275919628 Accuracy:  0.94615\n",
      "Iteration:  23850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23850 Loss:  0.19150237222705788 Accuracy:  0.94615\n",
      "Iteration:  23900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23900 Loss:  0.19150121663115724 Accuracy:  0.94615\n",
      "Iteration:  23950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  23950 Loss:  0.19150006162817182 Accuracy:  0.94615\n",
      "Iteration:  24000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24000 Loss:  0.19149890669225536 Accuracy:  0.94615\n",
      "Iteration:  24050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24050 Loss:  0.19149775188869003 Accuracy:  0.9461666666666667\n",
      "Iteration:  24100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24100 Loss:  0.19149659745657954 Accuracy:  0.9461666666666667\n",
      "Iteration:  24150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24150 Loss:  0.19149544321494072 Accuracy:  0.9461833333333334\n",
      "Iteration:  24200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24200 Loss:  0.19149428937731267 Accuracy:  0.9461833333333334\n",
      "Iteration:  24250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24250 Loss:  0.19149313502791077 Accuracy:  0.9461833333333334\n",
      "Iteration:  24300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24300 Loss:  0.1914919810274479 Accuracy:  0.9461833333333334\n",
      "Iteration:  24350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24350 Loss:  0.1914908270659937 Accuracy:  0.9461833333333334\n",
      "Iteration:  24400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24400 Loss:  0.19148967327259403 Accuracy:  0.9461833333333334\n",
      "Iteration:  24450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24450 Loss:  0.1914885199340299 Accuracy:  0.9461833333333334\n",
      "Iteration:  24500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24500 Loss:  0.19148736659592697 Accuracy:  0.9461833333333334\n",
      "Iteration:  24550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24550 Loss:  0.19148621356056392 Accuracy:  0.9461833333333334\n",
      "Iteration:  24600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24600 Loss:  0.19148506067473867 Accuracy:  0.9461833333333334\n",
      "Iteration:  24650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24650 Loss:  0.19148390824808553 Accuracy:  0.9461833333333334\n",
      "Iteration:  24700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24700 Loss:  0.19148275566851666 Accuracy:  0.9461833333333334\n",
      "Iteration:  24750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24750 Loss:  0.19148160327768332 Accuracy:  0.9461833333333334\n",
      "Iteration:  24800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24800 Loss:  0.1914804511914331 Accuracy:  0.9461833333333334\n",
      "Iteration:  24850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24850 Loss:  0.19147929947338935 Accuracy:  0.9461833333333334\n",
      "Iteration:  24900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24900 Loss:  0.19147814775980984 Accuracy:  0.9461833333333334\n",
      "Iteration:  24950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  24950 Loss:  0.1914769957928008 Accuracy:  0.9461833333333334\n",
      "Iteration:  25000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25000 Loss:  0.19147584402628556 Accuracy:  0.9461833333333334\n",
      "Iteration:  25050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25050 Loss:  0.1914746926420526 Accuracy:  0.9461833333333334\n",
      "Iteration:  25100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25100 Loss:  0.19147354164866798 Accuracy:  0.9461833333333334\n",
      "Iteration:  25150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25150 Loss:  0.19147239093184462 Accuracy:  0.9461833333333334\n",
      "Iteration:  25200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25200 Loss:  0.19147124048057554 Accuracy:  0.9461833333333334\n",
      "Iteration:  25250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25250 Loss:  0.19147009008287513 Accuracy:  0.9461833333333334\n",
      "Iteration:  25300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25300 Loss:  0.19146893996277517 Accuracy:  0.9461833333333334\n",
      "Iteration:  25350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25350 Loss:  0.19146779018731983 Accuracy:  0.9461833333333334\n",
      "Iteration:  25400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25400 Loss:  0.1914666404346044 Accuracy:  0.9462\n",
      "Iteration:  25450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25450 Loss:  0.19146549095040774 Accuracy:  0.9462\n",
      "Iteration:  25500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25500 Loss:  0.19146434144971813 Accuracy:  0.9462\n",
      "Iteration:  25550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25550 Loss:  0.19146319244762441 Accuracy:  0.9462\n",
      "Iteration:  25600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25600 Loss:  0.1914620434487425 Accuracy:  0.9462\n",
      "Iteration:  25650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25650 Loss:  0.19146089457009105 Accuracy:  0.9462\n",
      "Iteration:  25700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25700 Loss:  0.191459745965399 Accuracy:  0.9462\n",
      "Iteration:  25750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25750 Loss:  0.1914585972875244 Accuracy:  0.9462\n",
      "Iteration:  25800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25800 Loss:  0.19145744871701414 Accuracy:  0.9462\n",
      "Iteration:  25850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25850 Loss:  0.19145630021451038 Accuracy:  0.9462\n",
      "Iteration:  25900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25900 Loss:  0.19145515204306618 Accuracy:  0.9462166666666667\n",
      "Iteration:  25950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  25950 Loss:  0.191454003952162 Accuracy:  0.9462166666666667\n",
      "Iteration:  26000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26000 Loss:  0.19145285621397612 Accuracy:  0.9462166666666667\n",
      "Iteration:  26050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26050 Loss:  0.19145170841459758 Accuracy:  0.9462166666666667\n",
      "Iteration:  26100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26100 Loss:  0.1914505608855507 Accuracy:  0.9462333333333334\n",
      "Iteration:  26150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26150 Loss:  0.19144941354003597 Accuracy:  0.94625\n",
      "Iteration:  26200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26200 Loss:  0.19144826639039 Accuracy:  0.94625\n",
      "Iteration:  26250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26250 Loss:  0.19144711933359565 Accuracy:  0.94625\n",
      "Iteration:  26300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26300 Loss:  0.1914459725596844 Accuracy:  0.94625\n",
      "Iteration:  26350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26350 Loss:  0.19144482551564537 Accuracy:  0.94625\n",
      "Iteration:  26400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26400 Loss:  0.19144367864927225 Accuracy:  0.94625\n",
      "Iteration:  26450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26450 Loss:  0.19144253202343495 Accuracy:  0.94625\n",
      "Iteration:  26500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26500 Loss:  0.19144138530839258 Accuracy:  0.94625\n",
      "Iteration:  26550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26550 Loss:  0.19144023891677803 Accuracy:  0.94625\n",
      "Iteration:  26600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26600 Loss:  0.19143909278038804 Accuracy:  0.94625\n",
      "Iteration:  26650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26650 Loss:  0.19143794673161207 Accuracy:  0.94625\n",
      "Iteration:  26700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26700 Loss:  0.19143680090541598 Accuracy:  0.9462333333333334\n",
      "Iteration:  26750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26750 Loss:  0.19143565523725825 Accuracy:  0.9462333333333334\n",
      "Iteration:  26800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26800 Loss:  0.19143450917949686 Accuracy:  0.9462333333333334\n",
      "Iteration:  26850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26850 Loss:  0.19143336326332266 Accuracy:  0.9462333333333334\n",
      "Iteration:  26900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26900 Loss:  0.19143221750538916 Accuracy:  0.9462333333333334\n",
      "Iteration:  26950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  26950 Loss:  0.19143107229678036 Accuracy:  0.9462333333333334\n",
      "Iteration:  27000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27000 Loss:  0.19142992717698204 Accuracy:  0.9462333333333334\n",
      "Iteration:  27050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27050 Loss:  0.19142878195681653 Accuracy:  0.9462333333333334\n",
      "Iteration:  27100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27100 Loss:  0.19142763708647093 Accuracy:  0.9462333333333334\n",
      "Iteration:  27150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27150 Loss:  0.19142649227381825 Accuracy:  0.9462333333333334\n",
      "Iteration:  27200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27200 Loss:  0.19142534765464916 Accuracy:  0.9462333333333334\n",
      "Iteration:  27250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27250 Loss:  0.1914242034145358 Accuracy:  0.9462333333333334\n",
      "Iteration:  27300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27300 Loss:  0.19142305903562662 Accuracy:  0.9462333333333334\n",
      "Iteration:  27350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27350 Loss:  0.19142191486256538 Accuracy:  0.9462333333333334\n",
      "Iteration:  27400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27400 Loss:  0.19142077111360947 Accuracy:  0.9462333333333334\n",
      "Iteration:  27450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27450 Loss:  0.19141962714304825 Accuracy:  0.9462333333333334\n",
      "Iteration:  27500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27500 Loss:  0.19141848346829357 Accuracy:  0.9462333333333334\n",
      "Iteration:  27550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27550 Loss:  0.19141734014489362 Accuracy:  0.9462333333333334\n",
      "Iteration:  27600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27600 Loss:  0.19141619658738862 Accuracy:  0.9462333333333334\n",
      "Iteration:  27650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27650 Loss:  0.19141505330875533 Accuracy:  0.94625\n",
      "Iteration:  27700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27700 Loss:  0.1914139101377214 Accuracy:  0.94625\n",
      "Iteration:  27750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27750 Loss:  0.19141276691348166 Accuracy:  0.94625\n",
      "Iteration:  27800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27800 Loss:  0.19141162406455073 Accuracy:  0.94625\n",
      "Iteration:  27850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27850 Loss:  0.19141048119138002 Accuracy:  0.94625\n",
      "Iteration:  27900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27900 Loss:  0.19140933850128022 Accuracy:  0.94625\n",
      "Iteration:  27950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  27950 Loss:  0.19140819602563494 Accuracy:  0.94625\n",
      "Iteration:  28000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28000 Loss:  0.1914070532684251 Accuracy:  0.94625\n",
      "Iteration:  28050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28050 Loss:  0.1914059097719976 Accuracy:  0.94625\n",
      "Iteration:  28100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28100 Loss:  0.19140476664501252 Accuracy:  0.94625\n",
      "Iteration:  28150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28150 Loss:  0.19140362352867762 Accuracy:  0.94625\n",
      "Iteration:  28200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28200 Loss:  0.19140248081322786 Accuracy:  0.94625\n",
      "Iteration:  28250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28250 Loss:  0.191401337937628 Accuracy:  0.94625\n",
      "Iteration:  28300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28300 Loss:  0.19140019551118895 Accuracy:  0.94625\n",
      "Iteration:  28350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28350 Loss:  0.19139905312051048 Accuracy:  0.94625\n",
      "Iteration:  28400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28400 Loss:  0.1913979110696777 Accuracy:  0.94625\n",
      "Iteration:  28450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28450 Loss:  0.19139676912830197 Accuracy:  0.94625\n",
      "Iteration:  28500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28500 Loss:  0.191395627362122 Accuracy:  0.94625\n",
      "Iteration:  28550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28550 Loss:  0.19139448585558774 Accuracy:  0.9462666666666667\n",
      "Iteration:  28600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28600 Loss:  0.19139334424570636 Accuracy:  0.9462666666666667\n",
      "Iteration:  28650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28650 Loss:  0.19139220291838216 Accuracy:  0.9462666666666667\n",
      "Iteration:  28700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28700 Loss:  0.19139106236052914 Accuracy:  0.9462666666666667\n",
      "Iteration:  28750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28750 Loss:  0.19138992210261277 Accuracy:  0.9462666666666667\n",
      "Iteration:  28800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28800 Loss:  0.1913887817948226 Accuracy:  0.9462666666666667\n",
      "Iteration:  28850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28850 Loss:  0.1913876418922179 Accuracy:  0.9462666666666667\n",
      "Iteration:  28900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28900 Loss:  0.19138650221374143 Accuracy:  0.9462666666666667\n",
      "Iteration:  28950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  28950 Loss:  0.19138536262735928 Accuracy:  0.9462666666666667\n",
      "Iteration:  29000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29000 Loss:  0.1913842231582471 Accuracy:  0.9462666666666667\n",
      "Iteration:  29050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29050 Loss:  0.19138308356533423 Accuracy:  0.9462666666666667\n",
      "Iteration:  29100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29100 Loss:  0.19138194447088272 Accuracy:  0.9462666666666667\n",
      "Iteration:  29150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29150 Loss:  0.19138080559851633 Accuracy:  0.9462666666666667\n",
      "Iteration:  29200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29200 Loss:  0.1913796654867546 Accuracy:  0.9462666666666667\n",
      "Iteration:  29250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29250 Loss:  0.19137852280566364 Accuracy:  0.9462666666666667\n",
      "Iteration:  29300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29300 Loss:  0.19137738032831955 Accuracy:  0.9462833333333334\n",
      "Iteration:  29350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29350 Loss:  0.19137623821536118 Accuracy:  0.9462833333333334\n",
      "Iteration:  29400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29400 Loss:  0.19137509636119762 Accuracy:  0.9462833333333334\n",
      "Iteration:  29450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29450 Loss:  0.19137395451838543 Accuracy:  0.9462833333333334\n",
      "Iteration:  29500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29500 Loss:  0.1913728127293626 Accuracy:  0.9462833333333334\n",
      "Iteration:  29550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29550 Loss:  0.1913716712853848 Accuracy:  0.9462833333333334\n",
      "Iteration:  29600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29600 Loss:  0.19137052970740978 Accuracy:  0.9462833333333334\n",
      "Iteration:  29650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29650 Loss:  0.19136938828433842 Accuracy:  0.9462833333333334\n",
      "Iteration:  29700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29700 Loss:  0.19136824739960526 Accuracy:  0.9462833333333334\n",
      "Iteration:  29750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29750 Loss:  0.19136710622947642 Accuracy:  0.9462833333333334\n",
      "Iteration:  29800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29800 Loss:  0.19136596525607116 Accuracy:  0.9462833333333334\n",
      "Iteration:  29850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29850 Loss:  0.1913648244167006 Accuracy:  0.9462833333333334\n",
      "Iteration:  29900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29900 Loss:  0.19136368389176822 Accuracy:  0.9462833333333334\n",
      "Iteration:  29950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  29950 Loss:  0.19136254353292573 Accuracy:  0.9462833333333334\n",
      "Iteration:  30000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30000 Loss:  0.19136140336775564 Accuracy:  0.9462833333333334\n",
      "Iteration:  30050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30050 Loss:  0.1913602632876998 Accuracy:  0.9463\n",
      "Iteration:  30100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30100 Loss:  0.19135912340185968 Accuracy:  0.9463\n",
      "Iteration:  30150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30150 Loss:  0.19135798350926828 Accuracy:  0.9463\n",
      "Iteration:  30200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30200 Loss:  0.19135684392443592 Accuracy:  0.9463\n",
      "Iteration:  30250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30250 Loss:  0.1913557046371616 Accuracy:  0.9463\n",
      "Iteration:  30300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30300 Loss:  0.19135456506917964 Accuracy:  0.9463\n",
      "Iteration:  30350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30350 Loss:  0.19135342624454654 Accuracy:  0.9463\n",
      "Iteration:  30400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30400 Loss:  0.19135228704149174 Accuracy:  0.9463\n",
      "Iteration:  30450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30450 Loss:  0.19135114827957922 Accuracy:  0.9463\n",
      "Iteration:  30500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30500 Loss:  0.19135000967484259 Accuracy:  0.9463\n",
      "Iteration:  30550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30550 Loss:  0.19134887141700027 Accuracy:  0.9463\n",
      "Iteration:  30600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30600 Loss:  0.19134773331215232 Accuracy:  0.9463\n",
      "Iteration:  30650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30650 Loss:  0.19134659562308323 Accuracy:  0.9463\n",
      "Iteration:  30700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30700 Loss:  0.1913454577187555 Accuracy:  0.9463\n",
      "Iteration:  30750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30750 Loss:  0.19134432015049316 Accuracy:  0.9463\n",
      "Iteration:  30800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30800 Loss:  0.1913431828328189 Accuracy:  0.9463\n",
      "Iteration:  30850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30850 Loss:  0.19134204528251145 Accuracy:  0.9463\n",
      "Iteration:  30900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30900 Loss:  0.1913409080273692 Accuracy:  0.9463\n",
      "Iteration:  30950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30950 Loss:  0.19133977091082455 Accuracy:  0.9463\n",
      "Iteration:  31000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31000 Loss:  0.19133863379349758 Accuracy:  0.9463\n",
      "Iteration:  31050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31050 Loss:  0.19133749672438513 Accuracy:  0.9463\n",
      "Iteration:  31100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31100 Loss:  0.19133636006902455 Accuracy:  0.9463\n",
      "Iteration:  31150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31150 Loss:  0.19133522159949404 Accuracy:  0.9463\n",
      "Iteration:  31200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31200 Loss:  0.1913340829846528 Accuracy:  0.9463166666666667\n",
      "Iteration:  31250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31250 Loss:  0.19133294468674836 Accuracy:  0.9463166666666667\n",
      "Iteration:  31300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31300 Loss:  0.19133180664958585 Accuracy:  0.9463166666666667\n",
      "Iteration:  31350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31350 Loss:  0.1913306685856352 Accuracy:  0.9463166666666667\n",
      "Iteration:  31400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31400 Loss:  0.19132953086992946 Accuracy:  0.9463166666666667\n",
      "Iteration:  31450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31450 Loss:  0.19132839326299012 Accuracy:  0.9463166666666667\n",
      "Iteration:  31500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31500 Loss:  0.1913272554961206 Accuracy:  0.9463166666666667\n",
      "Iteration:  31550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31550 Loss:  0.19132611796334129 Accuracy:  0.9463166666666667\n",
      "Iteration:  31600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31600 Loss:  0.1913249807168565 Accuracy:  0.9463166666666667\n",
      "Iteration:  31650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31650 Loss:  0.19132384350542636 Accuracy:  0.9463166666666667\n",
      "Iteration:  31700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31700 Loss:  0.19132270653099828 Accuracy:  0.9463166666666667\n",
      "Iteration:  31750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31750 Loss:  0.19132156985077417 Accuracy:  0.9463166666666667\n",
      "Iteration:  31800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31800 Loss:  0.1913204329647813 Accuracy:  0.9463166666666667\n",
      "Iteration:  31850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31850 Loss:  0.19131929650353388 Accuracy:  0.9463166666666667\n",
      "Iteration:  31900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31900 Loss:  0.19131816002512692 Accuracy:  0.9463166666666667\n",
      "Iteration:  31950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  31950 Loss:  0.1913170222837275 Accuracy:  0.9463166666666667\n",
      "Iteration:  32000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32000 Loss:  0.19131588254855553 Accuracy:  0.9463166666666667\n",
      "Iteration:  32050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32050 Loss:  0.19131474354310488 Accuracy:  0.9463166666666667\n",
      "Iteration:  32100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32100 Loss:  0.19131360429814886 Accuracy:  0.9463166666666667\n",
      "Iteration:  32150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32150 Loss:  0.19131246553763234 Accuracy:  0.9463166666666667\n",
      "Iteration:  32200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32200 Loss:  0.19131132681453614 Accuracy:  0.9463166666666667\n",
      "Iteration:  32250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32250 Loss:  0.19131018818494558 Accuracy:  0.9463166666666667\n",
      "Iteration:  32300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32300 Loss:  0.1913090500809351 Accuracy:  0.9463166666666667\n",
      "Iteration:  32350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32350 Loss:  0.19130791185192805 Accuracy:  0.9463166666666667\n",
      "Iteration:  32400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32400 Loss:  0.19130677428980014 Accuracy:  0.9463166666666667\n",
      "Iteration:  32450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32450 Loss:  0.19130563642443865 Accuracy:  0.9463166666666667\n",
      "Iteration:  32500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32500 Loss:  0.19130449921468068 Accuracy:  0.9463166666666667\n",
      "Iteration:  32550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32550 Loss:  0.19130336190439753 Accuracy:  0.9463166666666667\n",
      "Iteration:  32600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32600 Loss:  0.19130222504723168 Accuracy:  0.9463166666666667\n",
      "Iteration:  32650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32650 Loss:  0.1913010886075649 Accuracy:  0.9463166666666667\n",
      "Iteration:  32700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32700 Loss:  0.19129995209107473 Accuracy:  0.9463166666666667\n",
      "Iteration:  32750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32750 Loss:  0.19129881589094466 Accuracy:  0.9463166666666667\n",
      "Iteration:  32800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32800 Loss:  0.1912976797578484 Accuracy:  0.9463166666666667\n",
      "Iteration:  32850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32850 Loss:  0.1912965439684955 Accuracy:  0.9463166666666667\n",
      "Iteration:  32900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32900 Loss:  0.19129540866384795 Accuracy:  0.9463166666666667\n",
      "Iteration:  32950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  32950 Loss:  0.19129427606378294 Accuracy:  0.9463166666666667\n",
      "Iteration:  33000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33000 Loss:  0.1912931432069069 Accuracy:  0.9463166666666667\n",
      "Iteration:  33050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33050 Loss:  0.19129201071117025 Accuracy:  0.9463166666666667\n",
      "Iteration:  33100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33100 Loss:  0.1912908784671218 Accuracy:  0.9463166666666667\n",
      "Iteration:  33150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33150 Loss:  0.19128974621140732 Accuracy:  0.9463166666666667\n",
      "Iteration:  33200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33200 Loss:  0.19128861399524796 Accuracy:  0.9463166666666667\n",
      "Iteration:  33250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33250 Loss:  0.19128748222677822 Accuracy:  0.9463166666666667\n",
      "Iteration:  33300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33300 Loss:  0.19128635046289094 Accuracy:  0.9463166666666667\n",
      "Iteration:  33350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33350 Loss:  0.19128521874699123 Accuracy:  0.9463166666666667\n",
      "Iteration:  33400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33400 Loss:  0.1912840872360328 Accuracy:  0.9463166666666667\n",
      "Iteration:  33450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33450 Loss:  0.19128295616835395 Accuracy:  0.9463166666666667\n",
      "Iteration:  33500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33500 Loss:  0.1912818248401146 Accuracy:  0.9463166666666667\n",
      "Iteration:  33550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33550 Loss:  0.1912806941272178 Accuracy:  0.9463166666666667\n",
      "Iteration:  33600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33600 Loss:  0.19127956329817988 Accuracy:  0.9463166666666667\n",
      "Iteration:  33650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33650 Loss:  0.19127843265156627 Accuracy:  0.9463166666666667\n",
      "Iteration:  33700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33700 Loss:  0.19127730223293923 Accuracy:  0.9463166666666667\n",
      "Iteration:  33750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33750 Loss:  0.19127617201341024 Accuracy:  0.9463166666666667\n",
      "Iteration:  33800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33800 Loss:  0.19127504190024708 Accuracy:  0.9463166666666667\n",
      "Iteration:  33850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33850 Loss:  0.19127391206438035 Accuracy:  0.9463166666666667\n",
      "Iteration:  33900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33900 Loss:  0.19127278043548593 Accuracy:  0.9463166666666667\n",
      "Iteration:  33950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  33950 Loss:  0.19127164659284296 Accuracy:  0.9463166666666667\n",
      "Iteration:  34000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34000 Loss:  0.1912705126857981 Accuracy:  0.9463166666666667\n",
      "Iteration:  34050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34050 Loss:  0.19126937861090967 Accuracy:  0.9463\n",
      "Iteration:  34100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34100 Loss:  0.19126823995733494 Accuracy:  0.9463\n",
      "Iteration:  34150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34150 Loss:  0.19126710105193437 Accuracy:  0.9463\n",
      "Iteration:  34200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34200 Loss:  0.1912659625074152 Accuracy:  0.9463\n",
      "Iteration:  34250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34250 Loss:  0.1912648238154963 Accuracy:  0.9463\n",
      "Iteration:  34300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34300 Loss:  0.19126368554681356 Accuracy:  0.9463\n",
      "Iteration:  34350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34350 Loss:  0.19126254725069372 Accuracy:  0.9463\n",
      "Iteration:  34400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34400 Loss:  0.19126140938837966 Accuracy:  0.9463\n",
      "Iteration:  34450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34450 Loss:  0.19126027141116034 Accuracy:  0.9463\n",
      "Iteration:  34500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34500 Loss:  0.19125913371821077 Accuracy:  0.9463\n",
      "Iteration:  34550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34550 Loss:  0.19125799631398702 Accuracy:  0.9463\n",
      "Iteration:  34600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34600 Loss:  0.19125685897118802 Accuracy:  0.9463\n",
      "Iteration:  34650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34650 Loss:  0.19125572189340295 Accuracy:  0.9463\n",
      "Iteration:  34700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34700 Loss:  0.1912545849707301 Accuracy:  0.9463\n",
      "Iteration:  34750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34750 Loss:  0.1912534480924556 Accuracy:  0.9463\n",
      "Iteration:  34800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34800 Loss:  0.19125231138690224 Accuracy:  0.9463\n",
      "Iteration:  34850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34850 Loss:  0.19125117493779223 Accuracy:  0.9463\n",
      "Iteration:  34900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34900 Loss:  0.19125003870695434 Accuracy:  0.9463\n",
      "Iteration:  34950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  34950 Loss:  0.19124890281695855 Accuracy:  0.9463\n",
      "Iteration:  35000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35000 Loss:  0.1912477668365564 Accuracy:  0.9463\n",
      "Iteration:  35050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35050 Loss:  0.19124663124504032 Accuracy:  0.9463\n",
      "Iteration:  35100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35100 Loss:  0.19124549623682235 Accuracy:  0.9463\n",
      "Iteration:  35150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35150 Loss:  0.19124436095189298 Accuracy:  0.9463\n",
      "Iteration:  35200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35200 Loss:  0.19124322539734412 Accuracy:  0.9463\n",
      "Iteration:  35250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35250 Loss:  0.1912420877080056 Accuracy:  0.9463\n",
      "Iteration:  35300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35300 Loss:  0.1912409502511711 Accuracy:  0.9463\n",
      "Iteration:  35350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35350 Loss:  0.19123981308310206 Accuracy:  0.9463\n",
      "Iteration:  35400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35400 Loss:  0.19123867611514433 Accuracy:  0.9463\n",
      "Iteration:  35450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35450 Loss:  0.19123753906927013 Accuracy:  0.9463\n",
      "Iteration:  35500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35500 Loss:  0.1912364022486364 Accuracy:  0.9463\n",
      "Iteration:  35550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35550 Loss:  0.19123526562774734 Accuracy:  0.9463\n",
      "Iteration:  35600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35600 Loss:  0.19123412933341308 Accuracy:  0.9463166666666667\n",
      "Iteration:  35650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35650 Loss:  0.19123299304316005 Accuracy:  0.9463166666666667\n",
      "Iteration:  35700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35700 Loss:  0.19123185695623338 Accuracy:  0.9463166666666667\n",
      "Iteration:  35750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35750 Loss:  0.1912307210629427 Accuracy:  0.9463166666666667\n",
      "Iteration:  35800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35800 Loss:  0.19122958520971184 Accuracy:  0.9463166666666667\n",
      "Iteration:  35850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35850 Loss:  0.19122844941526038 Accuracy:  0.9463166666666667\n",
      "Iteration:  35900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35900 Loss:  0.19122731406597107 Accuracy:  0.9463166666666667\n",
      "Iteration:  35950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  35950 Loss:  0.19122617876244247 Accuracy:  0.9463166666666667\n",
      "Iteration:  36000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36000 Loss:  0.19122504358584272 Accuracy:  0.9463166666666667\n",
      "Iteration:  36050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36050 Loss:  0.19122390760684016 Accuracy:  0.9463333333333334\n",
      "Iteration:  36100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36100 Loss:  0.19122277205443788 Accuracy:  0.9463333333333334\n",
      "Iteration:  36150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36150 Loss:  0.19122163666217565 Accuracy:  0.9463333333333334\n",
      "Iteration:  36200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36200 Loss:  0.19122050111065864 Accuracy:  0.9463333333333334\n",
      "Iteration:  36250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36250 Loss:  0.19121936572819676 Accuracy:  0.9463333333333334\n",
      "Iteration:  36300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36300 Loss:  0.19121823049879413 Accuracy:  0.9463333333333334\n",
      "Iteration:  36350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36350 Loss:  0.19121709545808688 Accuracy:  0.9463333333333334\n",
      "Iteration:  36400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36400 Loss:  0.1912159603315863 Accuracy:  0.9463333333333334\n",
      "Iteration:  36450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36450 Loss:  0.19121482594810166 Accuracy:  0.9463333333333334\n",
      "Iteration:  36500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36500 Loss:  0.19121369135940197 Accuracy:  0.9463166666666667\n",
      "Iteration:  36550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36550 Loss:  0.19121255746743698 Accuracy:  0.9463166666666667\n",
      "Iteration:  36600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36600 Loss:  0.1912114231193898 Accuracy:  0.9463166666666667\n",
      "Iteration:  36650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36650 Loss:  0.191210289273274 Accuracy:  0.9463166666666667\n",
      "Iteration:  36700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36700 Loss:  0.1912091555348378 Accuracy:  0.9463166666666667\n",
      "Iteration:  36750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36750 Loss:  0.19120802219357913 Accuracy:  0.9463333333333334\n",
      "Iteration:  36800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36800 Loss:  0.1912068887651834 Accuracy:  0.9463333333333334\n",
      "Iteration:  36850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36850 Loss:  0.19120575557699737 Accuracy:  0.9463333333333334\n",
      "Iteration:  36900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36900 Loss:  0.1912046226901301 Accuracy:  0.9463333333333334\n",
      "Iteration:  36950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  36950 Loss:  0.19120348989728375 Accuracy:  0.9463333333333334\n",
      "Iteration:  37000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37000 Loss:  0.19120235735253255 Accuracy:  0.9463333333333334\n",
      "Iteration:  37050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37050 Loss:  0.19120122535084738 Accuracy:  0.9463333333333334\n",
      "Iteration:  37100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37100 Loss:  0.19120009328253362 Accuracy:  0.9463333333333334\n",
      "Iteration:  37150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37150 Loss:  0.19119896130367703 Accuracy:  0.9463333333333334\n",
      "Iteration:  37200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37200 Loss:  0.19119782962308673 Accuracy:  0.9463333333333334\n",
      "Iteration:  37250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37250 Loss:  0.19119669796716077 Accuracy:  0.9463333333333334\n",
      "Iteration:  37300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37300 Loss:  0.19119556628802198 Accuracy:  0.9463333333333334\n",
      "Iteration:  37350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37350 Loss:  0.19119443490458093 Accuracy:  0.9463333333333334\n",
      "Iteration:  37400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37400 Loss:  0.19119330376955196 Accuracy:  0.94635\n",
      "Iteration:  37450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37450 Loss:  0.19119217276007802 Accuracy:  0.94635\n",
      "Iteration:  37500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37500 Loss:  0.1911910416358541 Accuracy:  0.94635\n",
      "Iteration:  37550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37550 Loss:  0.1911899104708272 Accuracy:  0.94635\n",
      "Iteration:  37600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37600 Loss:  0.1911887784540524 Accuracy:  0.94635\n",
      "Iteration:  37650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37650 Loss:  0.1911876466814588 Accuracy:  0.94635\n",
      "Iteration:  37700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37700 Loss:  0.19118651499031697 Accuracy:  0.94635\n",
      "Iteration:  37750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37750 Loss:  0.19118538352553271 Accuracy:  0.94635\n",
      "Iteration:  37800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37800 Loss:  0.1911842522156715 Accuracy:  0.94635\n",
      "Iteration:  37850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37850 Loss:  0.19118312081784383 Accuracy:  0.94635\n",
      "Iteration:  37900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37900 Loss:  0.19118199012451723 Accuracy:  0.94635\n",
      "Iteration:  37950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  37950 Loss:  0.19118085913364175 Accuracy:  0.94635\n",
      "Iteration:  38000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38000 Loss:  0.19117972817229378 Accuracy:  0.94635\n",
      "Iteration:  38050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38050 Loss:  0.19117859764906933 Accuracy:  0.94635\n",
      "Iteration:  38100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38100 Loss:  0.19117746725343226 Accuracy:  0.94635\n",
      "Iteration:  38150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38150 Loss:  0.19117633677572274 Accuracy:  0.94635\n",
      "Iteration:  38200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38200 Loss:  0.1911752066019003 Accuracy:  0.94635\n",
      "Iteration:  38250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38250 Loss:  0.19117407670831427 Accuracy:  0.94635\n",
      "Iteration:  38300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38300 Loss:  0.19117294671465843 Accuracy:  0.94635\n",
      "Iteration:  38350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38350 Loss:  0.19117181689852125 Accuracy:  0.94635\n",
      "Iteration:  38400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38400 Loss:  0.19117068723201155 Accuracy:  0.94635\n",
      "Iteration:  38450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38450 Loss:  0.19116955770918884 Accuracy:  0.94635\n",
      "Iteration:  38500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38500 Loss:  0.1911684284470691 Accuracy:  0.94635\n",
      "Iteration:  38550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38550 Loss:  0.19116729933407256 Accuracy:  0.94635\n",
      "Iteration:  38600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38600 Loss:  0.19116617030824512 Accuracy:  0.94635\n",
      "Iteration:  38650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38650 Loss:  0.19116504130735773 Accuracy:  0.94635\n",
      "Iteration:  38700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38700 Loss:  0.19116391255037252 Accuracy:  0.94635\n",
      "Iteration:  38750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38750 Loss:  0.19116278419607025 Accuracy:  0.94635\n",
      "Iteration:  38800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38800 Loss:  0.19116165583924608 Accuracy:  0.94635\n",
      "Iteration:  38850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38850 Loss:  0.19116052655153254 Accuracy:  0.94635\n",
      "Iteration:  38900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38900 Loss:  0.19115939564918086 Accuracy:  0.94635\n",
      "Iteration:  38950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  38950 Loss:  0.1911582645752807 Accuracy:  0.94635\n",
      "Iteration:  39000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39000 Loss:  0.19115713343341106 Accuracy:  0.94635\n",
      "Iteration:  39050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39050 Loss:  0.19115600263344637 Accuracy:  0.94635\n",
      "Iteration:  39100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39100 Loss:  0.19115487185755575 Accuracy:  0.94635\n",
      "Iteration:  39150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39150 Loss:  0.19115374152482414 Accuracy:  0.94635\n",
      "Iteration:  39200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39200 Loss:  0.19115261119443336 Accuracy:  0.94635\n",
      "Iteration:  39250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39250 Loss:  0.19115148106585103 Accuracy:  0.94635\n",
      "Iteration:  39300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39300 Loss:  0.19115035091754176 Accuracy:  0.94635\n",
      "Iteration:  39350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39350 Loss:  0.19114922080981953 Accuracy:  0.94635\n",
      "Iteration:  39400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39400 Loss:  0.191148091193521 Accuracy:  0.94635\n",
      "Iteration:  39450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39450 Loss:  0.19114696153763872 Accuracy:  0.94635\n",
      "Iteration:  39500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39500 Loss:  0.19114583204674804 Accuracy:  0.94635\n",
      "Iteration:  39550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39550 Loss:  0.19114470303311734 Accuracy:  0.94635\n",
      "Iteration:  39600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39600 Loss:  0.1911435738909417 Accuracy:  0.94635\n",
      "Iteration:  39650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39650 Loss:  0.19114244483928833 Accuracy:  0.94635\n",
      "Iteration:  39700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39700 Loss:  0.19114131598646986 Accuracy:  0.94635\n",
      "Iteration:  39750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39750 Loss:  0.1911401871363847 Accuracy:  0.94635\n",
      "Iteration:  39800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39800 Loss:  0.19113905869539402 Accuracy:  0.94635\n",
      "Iteration:  39850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39850 Loss:  0.1911379304690135 Accuracy:  0.94635\n",
      "Iteration:  39900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39900 Loss:  0.19113680253071763 Accuracy:  0.94635\n",
      "Iteration:  39950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  39950 Loss:  0.1911356745479567 Accuracy:  0.94635\n",
      "Iteration:  40000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40000 Loss:  0.1911345468115681 Accuracy:  0.94635\n",
      "Iteration:  40050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40050 Loss:  0.19113341905835818 Accuracy:  0.94635\n",
      "Iteration:  40100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40100 Loss:  0.19113229161222753 Accuracy:  0.94635\n",
      "Iteration:  40150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40150 Loss:  0.19113116434162702 Accuracy:  0.94635\n",
      "Iteration:  40200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40200 Loss:  0.1911300374726941 Accuracy:  0.94635\n",
      "Iteration:  40250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40250 Loss:  0.19112891116517738 Accuracy:  0.94635\n",
      "Iteration:  40300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40300 Loss:  0.19112778436552633 Accuracy:  0.94635\n",
      "Iteration:  40350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40350 Loss:  0.19112665793161634 Accuracy:  0.94635\n",
      "Iteration:  40400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40400 Loss:  0.1911255318237485 Accuracy:  0.94635\n",
      "Iteration:  40450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40450 Loss:  0.19112440585519969 Accuracy:  0.94635\n",
      "Iteration:  40500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40500 Loss:  0.19112327981698127 Accuracy:  0.94635\n",
      "Iteration:  40550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40550 Loss:  0.19112215402318464 Accuracy:  0.9463333333333334\n",
      "Iteration:  40600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40600 Loss:  0.19112102721383561 Accuracy:  0.9463333333333334\n",
      "Iteration:  40650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40650 Loss:  0.19111989944049962 Accuracy:  0.9463333333333334\n",
      "Iteration:  40700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40700 Loss:  0.19111877207858577 Accuracy:  0.9463333333333334\n",
      "Iteration:  40750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40750 Loss:  0.19111764464721365 Accuracy:  0.9463333333333334\n",
      "Iteration:  40800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40800 Loss:  0.1911165171548746 Accuracy:  0.9463333333333334\n",
      "Iteration:  40850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40850 Loss:  0.19111539019596635 Accuracy:  0.9463333333333334\n",
      "Iteration:  40900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40900 Loss:  0.19111426320394562 Accuracy:  0.9463333333333334\n",
      "Iteration:  40950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40950 Loss:  0.1911131363350997 Accuracy:  0.9463333333333334\n",
      "Iteration:  41000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41000 Loss:  0.19111200952235305 Accuracy:  0.9463333333333334\n",
      "Iteration:  41050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41050 Loss:  0.19111088318630415 Accuracy:  0.94635\n",
      "Iteration:  41100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41100 Loss:  0.1911097566554332 Accuracy:  0.94635\n",
      "Iteration:  41150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41150 Loss:  0.19110863030278924 Accuracy:  0.94635\n",
      "Iteration:  41200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41200 Loss:  0.19110750395418347 Accuracy:  0.94635\n",
      "Iteration:  41250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41250 Loss:  0.19110637772362996 Accuracy:  0.94635\n",
      "Iteration:  41300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41300 Loss:  0.19110525159849492 Accuracy:  0.94635\n",
      "Iteration:  41350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41350 Loss:  0.19110412576480684 Accuracy:  0.94635\n",
      "Iteration:  41400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41400 Loss:  0.1911029999958272 Accuracy:  0.9463666666666667\n",
      "Iteration:  41450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41450 Loss:  0.19110187433503503 Accuracy:  0.9463666666666667\n",
      "Iteration:  41500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41500 Loss:  0.1911007487419013 Accuracy:  0.9463666666666667\n",
      "Iteration:  41550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41550 Loss:  0.19109962331579697 Accuracy:  0.9463666666666667\n",
      "Iteration:  41600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41600 Loss:  0.19109849805157825 Accuracy:  0.9463666666666667\n",
      "Iteration:  41650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41650 Loss:  0.19109737325155257 Accuracy:  0.9463666666666667\n",
      "Iteration:  41700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41700 Loss:  0.19109624837885192 Accuracy:  0.9463666666666667\n",
      "Iteration:  41750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41750 Loss:  0.19109512357330935 Accuracy:  0.9463666666666667\n",
      "Iteration:  41800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41800 Loss:  0.19109399897384866 Accuracy:  0.9463666666666667\n",
      "Iteration:  41850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41850 Loss:  0.19109287448384693 Accuracy:  0.9463666666666667\n",
      "Iteration:  41900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41900 Loss:  0.19109175008822588 Accuracy:  0.9463666666666667\n",
      "Iteration:  41950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  41950 Loss:  0.19109062608042968 Accuracy:  0.9463666666666667\n",
      "Iteration:  42000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42000 Loss:  0.19108950208362516 Accuracy:  0.9463666666666667\n",
      "Iteration:  42050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42050 Loss:  0.19108837825897163 Accuracy:  0.9463666666666667\n",
      "Iteration:  42100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42100 Loss:  0.191087254709474 Accuracy:  0.9463666666666667\n",
      "Iteration:  42150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42150 Loss:  0.1910861314570056 Accuracy:  0.9463666666666667\n",
      "Iteration:  42200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42200 Loss:  0.19108500822716934 Accuracy:  0.9463666666666667\n",
      "Iteration:  42250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42250 Loss:  0.1910838848661943 Accuracy:  0.9463833333333334\n",
      "Iteration:  42300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42300 Loss:  0.19108276201985616 Accuracy:  0.9463833333333334\n",
      "Iteration:  42350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42350 Loss:  0.1910816392320482 Accuracy:  0.9463833333333334\n",
      "Iteration:  42400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42400 Loss:  0.19108051634415335 Accuracy:  0.9463833333333334\n",
      "Iteration:  42450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42450 Loss:  0.19107939384223938 Accuracy:  0.9463833333333334\n",
      "Iteration:  42500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42500 Loss:  0.19107827124932766 Accuracy:  0.9463833333333334\n",
      "Iteration:  42550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42550 Loss:  0.19107714840078 Accuracy:  0.9463833333333334\n",
      "Iteration:  42600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42600 Loss:  0.19107602458290499 Accuracy:  0.9463833333333334\n",
      "Iteration:  42650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42650 Loss:  0.19107490093574944 Accuracy:  0.9463833333333334\n",
      "Iteration:  42700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42700 Loss:  0.19107377753413846 Accuracy:  0.9463833333333334\n",
      "Iteration:  42750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42750 Loss:  0.19107265388963834 Accuracy:  0.9463833333333334\n",
      "Iteration:  42800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42800 Loss:  0.19107153050908482 Accuracy:  0.9463833333333334\n",
      "Iteration:  42850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42850 Loss:  0.19107040713336154 Accuracy:  0.9463833333333334\n",
      "Iteration:  42900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42900 Loss:  0.19106928381965002 Accuracy:  0.9463833333333334\n",
      "Iteration:  42950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  42950 Loss:  0.19106816053010997 Accuracy:  0.9463833333333334\n",
      "Iteration:  43000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43000 Loss:  0.1910670369502597 Accuracy:  0.9463833333333334\n",
      "Iteration:  43050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43050 Loss:  0.19106591390218405 Accuracy:  0.9463833333333334\n",
      "Iteration:  43100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43100 Loss:  0.19106479106018034 Accuracy:  0.9463833333333334\n",
      "Iteration:  43150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43150 Loss:  0.1910636682940396 Accuracy:  0.9463833333333334\n",
      "Iteration:  43200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43200 Loss:  0.19106254549053986 Accuracy:  0.9463833333333334\n",
      "Iteration:  43250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43250 Loss:  0.19106142291642547 Accuracy:  0.9463833333333334\n",
      "Iteration:  43300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43300 Loss:  0.19106030046703484 Accuracy:  0.9463833333333334\n",
      "Iteration:  43350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43350 Loss:  0.19105917834474878 Accuracy:  0.9463833333333334\n",
      "Iteration:  43400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43400 Loss:  0.19105805623715347 Accuracy:  0.9463833333333334\n",
      "Iteration:  43450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43450 Loss:  0.1910569343407775 Accuracy:  0.9463833333333334\n",
      "Iteration:  43500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43500 Loss:  0.1910558122473711 Accuracy:  0.9463833333333334\n",
      "Iteration:  43550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43550 Loss:  0.19105469059750935 Accuracy:  0.9463833333333334\n",
      "Iteration:  43600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43600 Loss:  0.19105356904737103 Accuracy:  0.9463833333333334\n",
      "Iteration:  43650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43650 Loss:  0.19105244767172727 Accuracy:  0.9463833333333334\n",
      "Iteration:  43700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43700 Loss:  0.19105132650182974 Accuracy:  0.9463833333333334\n",
      "Iteration:  43750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43750 Loss:  0.1910502051373093 Accuracy:  0.9463833333333334\n",
      "Iteration:  43800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43800 Loss:  0.19104908404868876 Accuracy:  0.9463833333333334\n",
      "Iteration:  43850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43850 Loss:  0.19104796336582716 Accuracy:  0.9463833333333334\n",
      "Iteration:  43900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43900 Loss:  0.19104684266488442 Accuracy:  0.9463833333333334\n",
      "Iteration:  43950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  43950 Loss:  0.1910457217537317 Accuracy:  0.9463833333333334\n",
      "Iteration:  44000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44000 Loss:  0.19104460141627802 Accuracy:  0.9463833333333334\n",
      "Iteration:  44050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44050 Loss:  0.19104348096397622 Accuracy:  0.9463833333333334\n",
      "Iteration:  44100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44100 Loss:  0.19104236069058878 Accuracy:  0.9463833333333334\n",
      "Iteration:  44150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44150 Loss:  0.19104124055622532 Accuracy:  0.9463833333333334\n",
      "Iteration:  44200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44200 Loss:  0.19104012042546697 Accuracy:  0.9463833333333334\n",
      "Iteration:  44250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44250 Loss:  0.19103899243229436 Accuracy:  0.9463833333333334\n",
      "Iteration:  44300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44300 Loss:  0.1910378641608055 Accuracy:  0.9463833333333334\n",
      "Iteration:  44350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44350 Loss:  0.19103673624209233 Accuracy:  0.9463833333333334\n",
      "Iteration:  44400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44400 Loss:  0.19103560883959955 Accuracy:  0.9463833333333334\n",
      "Iteration:  44450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44450 Loss:  0.19103448156408248 Accuracy:  0.9463833333333334\n",
      "Iteration:  44500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44500 Loss:  0.1910333546770966 Accuracy:  0.9463833333333334\n",
      "Iteration:  44550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44550 Loss:  0.19103222790422578 Accuracy:  0.9463833333333334\n",
      "Iteration:  44600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44600 Loss:  0.1910311012284452 Accuracy:  0.9463833333333334\n",
      "Iteration:  44650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44650 Loss:  0.1910299750401082 Accuracy:  0.9463833333333334\n",
      "Iteration:  44700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44700 Loss:  0.19102884878688803 Accuracy:  0.9463833333333334\n",
      "Iteration:  44750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44750 Loss:  0.19102772277731378 Accuracy:  0.9463833333333334\n",
      "Iteration:  44800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44800 Loss:  0.19102659741757924 Accuracy:  0.9463833333333334\n",
      "Iteration:  44850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44850 Loss:  0.1910254717861391 Accuracy:  0.9464\n",
      "Iteration:  44900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44900 Loss:  0.19102434647070338 Accuracy:  0.9464\n",
      "Iteration:  44950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  44950 Loss:  0.19102322121638113 Accuracy:  0.9464\n",
      "Iteration:  45000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45000 Loss:  0.19102209641692386 Accuracy:  0.9464\n",
      "Iteration:  45050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45050 Loss:  0.19102097149776912 Accuracy:  0.9464\n",
      "Iteration:  45100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45100 Loss:  0.19101984689676849 Accuracy:  0.9464\n",
      "Iteration:  45150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45150 Loss:  0.19101872241033585 Accuracy:  0.9464\n",
      "Iteration:  45200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45200 Loss:  0.1910175980733468 Accuracy:  0.9464\n",
      "Iteration:  45250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45250 Loss:  0.19101647380274592 Accuracy:  0.9464\n",
      "Iteration:  45300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45300 Loss:  0.19101534991955232 Accuracy:  0.9464\n",
      "Iteration:  45350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45350 Loss:  0.1910142257181383 Accuracy:  0.9464\n",
      "Iteration:  45400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45400 Loss:  0.1910131015226455 Accuracy:  0.9464\n",
      "Iteration:  45450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45450 Loss:  0.1910119775105099 Accuracy:  0.9464\n",
      "Iteration:  45500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45500 Loss:  0.1910108537259902 Accuracy:  0.9464\n",
      "Iteration:  45550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45550 Loss:  0.19100972981261313 Accuracy:  0.9464\n",
      "Iteration:  45600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45600 Loss:  0.1910086061520711 Accuracy:  0.9464\n",
      "Iteration:  45650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45650 Loss:  0.19100748290750205 Accuracy:  0.9464\n",
      "Iteration:  45700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45700 Loss:  0.19100635971408486 Accuracy:  0.9464\n",
      "Iteration:  45750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45750 Loss:  0.19100523651400403 Accuracy:  0.9464\n",
      "Iteration:  45800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45800 Loss:  0.19100411374226878 Accuracy:  0.9464\n",
      "Iteration:  45850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45850 Loss:  0.19100299093823456 Accuracy:  0.9464166666666667\n",
      "Iteration:  45900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45900 Loss:  0.19100186839511465 Accuracy:  0.9464166666666667\n",
      "Iteration:  45950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  45950 Loss:  0.19100074568008224 Accuracy:  0.9464166666666667\n",
      "Iteration:  46000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46000 Loss:  0.1909996234094017 Accuracy:  0.9464166666666667\n",
      "Iteration:  46050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46050 Loss:  0.19099850072127544 Accuracy:  0.9464166666666667\n",
      "Iteration:  46100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46100 Loss:  0.1909973777145632 Accuracy:  0.9464166666666667\n",
      "Iteration:  46150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46150 Loss:  0.19099625474813245 Accuracy:  0.9464166666666667\n",
      "Iteration:  46200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46200 Loss:  0.19099513213642702 Accuracy:  0.9464166666666667\n",
      "Iteration:  46250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46250 Loss:  0.19099400967478694 Accuracy:  0.9464166666666667\n",
      "Iteration:  46300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46300 Loss:  0.19099288721710178 Accuracy:  0.9464166666666667\n",
      "Iteration:  46350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46350 Loss:  0.19099176522755004 Accuracy:  0.9464166666666667\n",
      "Iteration:  46400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46400 Loss:  0.1909906430226787 Accuracy:  0.9464166666666667\n",
      "Iteration:  46450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46450 Loss:  0.19098952094191562 Accuracy:  0.9464166666666667\n",
      "Iteration:  46500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46500 Loss:  0.1909883993617932 Accuracy:  0.9464166666666667\n",
      "Iteration:  46550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46550 Loss:  0.1909872778467604 Accuracy:  0.9464166666666667\n",
      "Iteration:  46600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46600 Loss:  0.19098615627555188 Accuracy:  0.9464166666666667\n",
      "Iteration:  46650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46650 Loss:  0.19098503511558182 Accuracy:  0.9464166666666667\n",
      "Iteration:  46700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46700 Loss:  0.19098391383645125 Accuracy:  0.9464166666666667\n",
      "Iteration:  46750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46750 Loss:  0.19098279268664647 Accuracy:  0.9464166666666667\n",
      "Iteration:  46800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46800 Loss:  0.19098167207320535 Accuracy:  0.9464166666666667\n",
      "Iteration:  46850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46850 Loss:  0.190980551468266 Accuracy:  0.9464166666666667\n",
      "Iteration:  46900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46900 Loss:  0.1909794310780512 Accuracy:  0.9464333333333333\n",
      "Iteration:  46950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  46950 Loss:  0.19097831073863455 Accuracy:  0.9464333333333333\n",
      "Iteration:  47000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47000 Loss:  0.19097719080192843 Accuracy:  0.9464333333333333\n",
      "Iteration:  47050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47050 Loss:  0.19097607073068706 Accuracy:  0.9464333333333333\n",
      "Iteration:  47100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47100 Loss:  0.19097494992256112 Accuracy:  0.9464333333333333\n",
      "Iteration:  47150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47150 Loss:  0.19097382908334284 Accuracy:  0.9464333333333333\n",
      "Iteration:  47200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47200 Loss:  0.1909727085335844 Accuracy:  0.9464333333333333\n",
      "Iteration:  47250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47250 Loss:  0.19097158806431247 Accuracy:  0.9464333333333333\n",
      "Iteration:  47300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47300 Loss:  0.19097046779823165 Accuracy:  0.9464166666666667\n",
      "Iteration:  47350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47350 Loss:  0.19096934785620143 Accuracy:  0.9464166666666667\n",
      "Iteration:  47400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47400 Loss:  0.19096822762968166 Accuracy:  0.9464166666666667\n",
      "Iteration:  47450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47450 Loss:  0.1909671079954566 Accuracy:  0.9464166666666667\n",
      "Iteration:  47500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47500 Loss:  0.19096598851176178 Accuracy:  0.9464166666666667\n",
      "Iteration:  47550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47550 Loss:  0.19096486878980756 Accuracy:  0.9464166666666667\n",
      "Iteration:  47600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47600 Loss:  0.19096374972585842 Accuracy:  0.9464166666666667\n",
      "Iteration:  47650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47650 Loss:  0.1909626308236938 Accuracy:  0.9464166666666667\n",
      "Iteration:  47700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47700 Loss:  0.1909615116997001 Accuracy:  0.9464166666666667\n",
      "Iteration:  47750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47750 Loss:  0.19096039291700714 Accuracy:  0.9464166666666667\n",
      "Iteration:  47800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47800 Loss:  0.19095927415522895 Accuracy:  0.9464166666666667\n",
      "Iteration:  47850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47850 Loss:  0.19095815577064748 Accuracy:  0.9464166666666667\n",
      "Iteration:  47900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47900 Loss:  0.19095703747444592 Accuracy:  0.9464166666666667\n",
      "Iteration:  47950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  47950 Loss:  0.190955919216772 Accuracy:  0.9464166666666667\n",
      "Iteration:  48000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48000 Loss:  0.19095480159859865 Accuracy:  0.9464166666666667\n",
      "Iteration:  48050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48050 Loss:  0.19095368344950947 Accuracy:  0.9464166666666667\n",
      "Iteration:  48100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48100 Loss:  0.19095256562949686 Accuracy:  0.9464166666666667\n",
      "Iteration:  48150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48150 Loss:  0.19095144800002162 Accuracy:  0.9464166666666667\n",
      "Iteration:  48200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48200 Loss:  0.19095033025667066 Accuracy:  0.9464166666666667\n",
      "Iteration:  48250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48250 Loss:  0.19094921260073058 Accuracy:  0.9464166666666667\n",
      "Iteration:  48300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48300 Loss:  0.19094809482617375 Accuracy:  0.9464166666666667\n",
      "Iteration:  48350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48350 Loss:  0.19094697694380797 Accuracy:  0.9464166666666667\n",
      "Iteration:  48400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48400 Loss:  0.1909458590364241 Accuracy:  0.9464166666666667\n",
      "Iteration:  48450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48450 Loss:  0.19094474082105836 Accuracy:  0.9464166666666667\n",
      "Iteration:  48500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48500 Loss:  0.19094362313675609 Accuracy:  0.9464166666666667\n",
      "Iteration:  48550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48550 Loss:  0.19094250550575576 Accuracy:  0.9464166666666667\n",
      "Iteration:  48600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48600 Loss:  0.19094138785756276 Accuracy:  0.9464166666666667\n",
      "Iteration:  48650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48650 Loss:  0.19094027058231214 Accuracy:  0.9464166666666667\n",
      "Iteration:  48700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48700 Loss:  0.19093915307002152 Accuracy:  0.9464166666666667\n",
      "Iteration:  48750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48750 Loss:  0.19093803598623735 Accuracy:  0.9464166666666667\n",
      "Iteration:  48800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48800 Loss:  0.19093691891200518 Accuracy:  0.9464166666666667\n",
      "Iteration:  48850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48850 Loss:  0.19093580205543884 Accuracy:  0.9464166666666667\n",
      "Iteration:  48900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48900 Loss:  0.1909346853301391 Accuracy:  0.9464166666666667\n",
      "Iteration:  48950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  48950 Loss:  0.19093356859259644 Accuracy:  0.9464166666666667\n",
      "Iteration:  49000\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49000 Loss:  0.1909324521912632 Accuracy:  0.9464166666666667\n",
      "Iteration:  49050\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49050 Loss:  0.19093133588188305 Accuracy:  0.9464166666666667\n",
      "Iteration:  49100\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49100 Loss:  0.19093021958999457 Accuracy:  0.9464166666666667\n",
      "Iteration:  49150\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49150 Loss:  0.19092910355307932 Accuracy:  0.9464333333333333\n",
      "Iteration:  49200\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49200 Loss:  0.19092798767270228 Accuracy:  0.9464333333333333\n",
      "Iteration:  49250\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49250 Loss:  0.19092687193096622 Accuracy:  0.9464333333333333\n",
      "Iteration:  49300\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49300 Loss:  0.19092575631129993 Accuracy:  0.9464333333333333\n",
      "Iteration:  49350\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49350 Loss:  0.19092464094656067 Accuracy:  0.9464333333333333\n",
      "Iteration:  49400\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49400 Loss:  0.19092352511139007 Accuracy:  0.9464333333333333\n",
      "Iteration:  49450\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49450 Loss:  0.19092240991918874 Accuracy:  0.9464333333333333\n",
      "Iteration:  49500\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49500 Loss:  0.1909212943030292 Accuracy:  0.9464333333333333\n",
      "Iteration:  49550\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49550 Loss:  0.1909201792402763 Accuracy:  0.9464333333333333\n",
      "Iteration:  49600\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49600 Loss:  0.19091906410417572 Accuracy:  0.9464333333333333\n",
      "Iteration:  49650\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49650 Loss:  0.19091794935173964 Accuracy:  0.9464333333333333\n",
      "Iteration:  49700\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49700 Loss:  0.19091683465373166 Accuracy:  0.9464333333333333\n",
      "Iteration:  49750\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49750 Loss:  0.19091572004480764 Accuracy:  0.9464333333333333\n",
      "Iteration:  49800\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49800 Loss:  0.1909146056725776 Accuracy:  0.9464333333333333\n",
      "Iteration:  49850\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49850 Loss:  0.1909134916584305 Accuracy:  0.9464333333333333\n",
      "Iteration:  49900\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49900 Loss:  0.1909123771455715 Accuracy:  0.9464333333333333\n",
      "Iteration:  49950\n",
      "[5 0 4 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  49950 Loss:  0.19091126314938847 Accuracy:  0.9464333333333333\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(train_X_flattened, train_y, iterations, alpha, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    # Extracting the image and reshaping it to column vector\n",
    "    current_image = train_X[index].reshape(784, 1) / 255.0\n",
    "    prediction = make_predictions(current_image, W1, b1, W2, b2)\n",
    "    label = train_y[index]\n",
    "    \n",
    "    print(\"Prediction: \", prediction[0])  # [0] to get the scalar value\n",
    "    print(\"Label: \", label)\n",
    "\n",
    "    # Reshaping the image for visualization\n",
    "    current_image = current_image.reshape((28, 28))\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  5\n",
      "Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(0, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import util "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_image(image, path, name):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    file_name = os.path.join(path, name + \".png\")\n",
    "    cv2.imwrite(file_name, image)\n",
    "    print(f\"Saved processed image to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(ROI, save_image=False, image_path='', image_name='image'):\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(ROI, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply binary thresholding\n",
    "    _, thresholded_image = cv2.threshold(gray_image, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Resize the image to 28x28\n",
    "    resized_image = cv2.resize(thresholded_image, (28, 28))\n",
    "\n",
    "    # Invert the grayscale image\n",
    "    inverted_image = cv2.bitwise_not(resized_image)\n",
    "\n",
    "    # Flatten the resized (and potentially inverted) image\n",
    "    flattened_image = inverted_image.flatten().reshape((784, 1))\n",
    "\n",
    "    # Save the processed image\n",
    "    if save_image:\n",
    "        cv2.imwrite(f'{image_path}/{image_name}.png', inverted_image)\n",
    "\n",
    "    return flattened_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"\n",
    "    Preprocess the frame to match MNIST dataset format.\n",
    "\n",
    "    frame: Captured image from the camera.\n",
    "    \n",
    "    Returns:\n",
    "    Processed image ready for prediction.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    if len(frame.shape) == 3 and frame.shape[2] == 3:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Resize to 28x28 (MNIST format)\n",
    "    frame_resized = cv2.resize(frame, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Invert colors if necessary (digit should be white on black background)\n",
    "    frame_inverted = cv2.bitwise_not(frame_resized)\n",
    "\n",
    "    # Normalize pixel values to be between 0 and 1\n",
    "    frame_normalized = frame_inverted / 255.0\n",
    "\n",
    "    # Flatten the image to a 784-element array\n",
    "    frame_flattened = frame_normalized.flatten().reshape(784, 1)\n",
    "\n",
    "    return frame_flattened\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_and_predict(W1, b1, W2, b2):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    ROI_size = 200\n",
    "    save_next_frame = False\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame, ROI = capture_frame(cap, ROI_size)\n",
    "        if not ret:\n",
    "            capture_and_predict(W1, b1, W2, b2)\n",
    "\n",
    "        # Check for space bar press to save the next frame\n",
    "        key = cv2.waitKey(10)\n",
    "        if key == 32:  # Space bar key code\n",
    "            save_next_frame = True\n",
    "\n",
    "        processed_ROI = preprocess_frame(ROI, save_image=save_next_frame, \n",
    "                                         image_path='images/processed_images/', \n",
    "                                         image_name='processed_img_{}'.format(frame_count))\n",
    "\n",
    "        # Reset save_next_frame after saving\n",
    "        if save_next_frame:\n",
    "            save_next_frame = False\n",
    "            frame_count += 1\n",
    "\n",
    "        predicted_digit = make_predictions(processed_ROI, W1, b1, W2, b2)[0]\n",
    "        display_prediction(frame, predicted_digit, ROI_size)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def capture_frame(cap, ROI_size):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        return False, frame, None\n",
    "\n",
    "    x_start, y_start = calculate_ROI_start(cap, ROI_size)\n",
    "    ROI = frame[y_start:y_start + ROI_size, x_start:x_start + ROI_size]\n",
    "    draw_ROI(frame, x_start, y_start, ROI_size)\n",
    "    return True, frame, ROI\n",
    "\n",
    "def calculate_ROI_start(cap, ROI_size):\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    x_start = (frame_width - ROI_size) // 2\n",
    "    y_start = (frame_height - ROI_size) // 2\n",
    "    return x_start, y_start\n",
    "\n",
    "def draw_ROI(frame, x_start, y_start, ROI_size):\n",
    "    cv2.rectangle(frame, (x_start, y_start), (x_start + ROI_size, y_start + ROI_size), (0, 255, 0), 3)\n",
    "\n",
    "def display_prediction(frame, predicted_digit, ROI_size):\n",
    "    cv2.putText(frame, f'Pred: {predicted_digit}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Digit Recognition', frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to initialize your model parameters (W1, b1, W2, b2) before calling this function\n",
    "capture_and_predict(W1, b1, W2, b2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
